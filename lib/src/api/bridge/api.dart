// This file is automatically generated, so please do not edit it.
// @generated by `flutter_rust_bridge`@ 2.10.0.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';
import 'package:freezed_annotation/freezed_annotation.dart' hide protected;

import 'api/media_info.dart';
import 'frb_generated.dart';
import 'lib.dart';
import 'renderer.dart';

part 'api.freezed.dart';

// These types are ignored because they are neither used by any `pub` functions nor (for structs and enums) marked `#[frb(unignore)]`: `TrackKind`
// These function are ignored because they are on traits that is not defined in current crate (put an empty `#[frb]` on it to unignore): `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `hash`, `hash`, `hash`

/// Returns all [`VideoCodecInfo`]s of the supported video encoders.
Future<List<VideoCodecInfo>> videoEncoders() =>
    RustLib.instance.api.crateApiVideoEncoders();

/// Returns all [`VideoCodecInfo`]s of the supported video decoders.
Future<List<VideoCodecInfo>> videoDecoders() =>
    RustLib.instance.api.crateApiVideoDecoders();

/// Configures media acquisition to use fake devices instead of actual camera
/// and microphone.
Future<void> enableFakeMedia() =>
    RustLib.instance.api.crateApiEnableFakeMedia();

/// Indicates whether application is configured to use fake media devices.
Future<bool> isFakeMedia() => RustLib.instance.api.crateApiIsFakeMedia();

/// Returns a list of all available media input and output devices, such as
/// microphones, cameras, headsets, and so forth.
Future<List<MediaDeviceInfo>> enumerateDevices() =>
    RustLib.instance.api.crateApiEnumerateDevices();

/// Returns a list of all available displays that can be used for screen
/// capturing.
Future<List<MediaDisplayInfo>> enumerateDisplays() =>
    RustLib.instance.api.crateApiEnumerateDisplays();

/// Creates a new [`PeerConnection`] and returns its ID.
Stream<PeerConnectionEvent> createPeerConnection({
  required RtcConfiguration configuration,
}) => RustLib.instance.api.crateApiCreatePeerConnection(
  configuration: configuration,
);

/// Initiates the creation of an SDP offer for the purpose of starting a new
/// WebRTC connection to a remote peer.
Future<RtcSessionDescription> createOffer({
  required ArcPeerConnection peer,
  required bool voiceActivityDetection,
  required bool iceRestart,
  required bool useRtpMux,
}) => RustLib.instance.api.crateApiCreateOffer(
  peer: peer,
  voiceActivityDetection: voiceActivityDetection,
  iceRestart: iceRestart,
  useRtpMux: useRtpMux,
);

/// Creates an SDP answer to an offer received from a remote peer during an
/// offer/answer negotiation of a WebRTC connection.
Future<RtcSessionDescription> createAnswer({
  required ArcPeerConnection peer,
  required bool voiceActivityDetection,
  required bool iceRestart,
  required bool useRtpMux,
}) => RustLib.instance.api.crateApiCreateAnswer(
  peer: peer,
  voiceActivityDetection: voiceActivityDetection,
  iceRestart: iceRestart,
  useRtpMux: useRtpMux,
);

/// Changes the local description associated with the connection.
Future<void> setLocalDescription({
  required ArcPeerConnection peer,
  required SdpType kind,
  required String sdp,
}) => RustLib.instance.api.crateApiSetLocalDescription(
  peer: peer,
  kind: kind,
  sdp: sdp,
);

/// Sets the specified session description as the remote peer's current offer or
/// answer.
Future<void> setRemoteDescription({
  required ArcPeerConnection peer,
  required SdpType kind,
  required String sdp,
}) => RustLib.instance.api.crateApiSetRemoteDescription(
  peer: peer,
  kind: kind,
  sdp: sdp,
);

/// Creates a new [`RtcRtpTransceiver`] and adds it to the set of transceivers
/// of the specified [`PeerConnection`].
Future<RtcRtpTransceiver> addTransceiver({
  required ArcPeerConnection peer,
  required MediaType mediaType,
  required RtpTransceiverInit init,
}) => RustLib.instance.api.crateApiAddTransceiver(
  peer: peer,
  mediaType: mediaType,
  init: init,
);

/// Returns a sequence of [`RtcRtpTransceiver`] objects representing the RTP
/// transceivers currently attached to the specified [`PeerConnection`].
Future<List<RtcRtpTransceiver>> getTransceivers({
  required ArcPeerConnection peer,
}) => RustLib.instance.api.crateApiGetTransceivers(peer: peer);

/// Changes the preferred `direction` of the specified [`RtcRtpTransceiver`].
Future<void> setTransceiverDirection({
  required ArcRtpTransceiver transceiver,
  required RtpTransceiverDirection direction,
}) => RustLib.instance.api.crateApiSetTransceiverDirection(
  transceiver: transceiver,
  direction: direction,
);

/// Changes the receive direction of the specified [`RtcRtpTransceiver`].
Future<void> setTransceiverRecv({
  required ArcRtpTransceiver transceiver,
  required bool recv,
}) => RustLib.instance.api.crateApiSetTransceiverRecv(
  transceiver: transceiver,
  recv: recv,
);

/// Changes the send direction of the specified [`RtcRtpTransceiver`].
Future<void> setTransceiverSend({
  required ArcRtpTransceiver transceiver,
  required bool send,
}) => RustLib.instance.api.crateApiSetTransceiverSend(
  transceiver: transceiver,
  send: send,
);

/// Returns the [negotiated media ID (mid)][1] of the specified
/// [`RtcRtpTransceiver`].
///
/// [1]: https://w3.org/TR/webrtc#dfn-media-stream-identification-tag
Future<String?> getTransceiverMid({required ArcRtpTransceiver transceiver}) =>
    RustLib.instance.api.crateApiGetTransceiverMid(transceiver: transceiver);

/// Returns the preferred direction of the specified [`RtcRtpTransceiver`].
Future<RtpTransceiverDirection> getTransceiverDirection({
  required ArcRtpTransceiver transceiver,
}) => RustLib.instance.api.crateApiGetTransceiverDirection(
  transceiver: transceiver,
);

/// Irreversibly marks the specified [`RtcRtpTransceiver`] as stopping, unless
/// it's already stopped.
///
/// This will immediately cause the transceiver's sender to no longer send, and
/// its receiver to no longer receive.
Future<void> stopTransceiver({required ArcRtpTransceiver transceiver}) =>
    RustLib.instance.api.crateApiStopTransceiver(transceiver: transceiver);

/// Changes the preferred [`RtpTransceiver`] codecs to the provided
/// [`Vec`]`<`[`RtpCodecCapability`]`>`.
Future<void> setCodecPreferences({
  required ArcRtpTransceiver transceiver,
  required List<RtpCodecCapability> codecs,
}) => RustLib.instance.api.crateApiSetCodecPreferences(
  transceiver: transceiver,
  codecs: codecs,
);

/// Replaces the specified [`AudioTrack`] (or [`VideoTrack`]) on the
/// [`sys::RtpTransceiverInterface`]'s `sender`.
///
/// [`AudioTrack`]: crate::AudioTrack
/// [`VideoTrack`]: crate::VideoTrack
Future<void> senderReplaceTrack({
  required ArcPeerConnection peer,
  required ArcRtpTransceiver transceiver,
  String? trackId,
}) => RustLib.instance.api.crateApiSenderReplaceTrack(
  peer: peer,
  transceiver: transceiver,
  trackId: trackId,
);

/// Returns [`RtpParameters`] from the provided [`RtpTransceiver`]'s `sender`.
Future<RtcRtpSendParameters> senderGetParameters({
  required ArcRtpTransceiver transceiver,
}) =>
    RustLib.instance.api.crateApiSenderGetParameters(transceiver: transceiver);

/// Returns the capabilities of an [RTP] sender of the provided [`MediaType`].
///
/// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
Future<RtpCapabilities> getRtpSenderCapabilities({required MediaType kind}) =>
    RustLib.instance.api.crateApiGetRtpSenderCapabilities(kind: kind);

/// Returns the capabilities of an [RTP] receiver of the provided [`MediaType`].
///
/// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
Future<RtpCapabilities> getRtpReceiverCapabilities({required MediaType kind}) =>
    RustLib.instance.api.crateApiGetRtpReceiverCapabilities(kind: kind);

/// Sets [`RtpParameters`] into the provided [`RtpTransceiver`]'s `sender`.
Future<void> senderSetParameters({
  required ArcRtpTransceiver transceiver,
  required RtcRtpSendParameters params,
}) => RustLib.instance.api.crateApiSenderSetParameters(
  transceiver: transceiver,
  params: params,
);

/// Adds the new ICE `candidate` to the given [`PeerConnection`].
Future<void> addIceCandidate({
  required ArcPeerConnection peer,
  required String candidate,
  required String sdpMid,
  required int sdpMlineIndex,
}) => RustLib.instance.api.crateApiAddIceCandidate(
  peer: peer,
  candidate: candidate,
  sdpMid: sdpMid,
  sdpMlineIndex: sdpMlineIndex,
);

/// Tells the [`PeerConnection`] that ICE should be restarted.
Future<void> restartIce({required ArcPeerConnection peer}) =>
    RustLib.instance.api.crateApiRestartIce(peer: peer);

/// Closes the [`PeerConnection`].
Future<void> disposePeerConnection({required ArcPeerConnection peer}) =>
    RustLib.instance.api.crateApiDisposePeerConnection(peer: peer);

/// Creates a [MediaStream] with tracks according to provided
/// [`MediaStreamConstraints`].
///
/// [MediaStream]: https://w3.org/TR/mediacapture-streams#dom-mediastream
Future<GetMediaResult> getMedia({
  required MediaStreamConstraints constraints,
}) => RustLib.instance.api.crateApiGetMedia(constraints: constraints);

/// Sets the specified `audio playout` device.
Future<void> setAudioPlayoutDevice({required String deviceId}) =>
    RustLib.instance.api.crateApiSetAudioPlayoutDevice(deviceId: deviceId);

/// Indicates whether the microphone is available to set volume.
Future<bool> microphoneVolumeIsAvailable() =>
    RustLib.instance.api.crateApiMicrophoneVolumeIsAvailable();

/// Sets the microphone system volume according to the specified `level` in
/// percents.
///
/// Valid values range is `[0; 100]`.
Future<void> setMicrophoneVolume({required int level}) =>
    RustLib.instance.api.crateApiSetMicrophoneVolume(level: level);

/// Returns the current level of the microphone volume in `[0; 100]` range.
Future<int> microphoneVolume() =>
    RustLib.instance.api.crateApiMicrophoneVolume();

/// Disposes the specified [`MediaStreamTrack`].
Future<void> disposeTrack({
  required String trackId,
  int? peerId,
  required MediaType kind,
}) => RustLib.instance.api.crateApiDisposeTrack(
  trackId: trackId,
  peerId: peerId,
  kind: kind,
);

/// Returns the [readyState][0] property of the [`MediaStreamTrack`] by its ID
/// and [`MediaType`].
///
/// [0]: https://w3.org/TR/mediacapture-streams#dfn-readystate
Future<TrackState> trackState({
  required String trackId,
  int? peerId,
  required MediaType kind,
}) => RustLib.instance.api.crateApiTrackState(
  trackId: trackId,
  peerId: peerId,
  kind: kind,
);

/// Returns the [height] property of the media track by its ID and
/// [`MediaType`].
///
/// Blocks until the [height] is initialized.
///
/// [height]: https://w3.org/TR/mediacapture-streams#dfn-height
Future<int?> trackHeight({
  required String trackId,
  int? peerId,
  required MediaType kind,
}) => RustLib.instance.api.crateApiTrackHeight(
  trackId: trackId,
  peerId: peerId,
  kind: kind,
);

/// Returns the [width] property of the media track by its ID and [`MediaType`].
///
/// Blocks until the [width] is initialized.
///
/// [width]: https://w3.org/TR/mediacapture-streams#dfn-height
Future<int?> trackWidth({
  required String trackId,
  int? peerId,
  required MediaType kind,
}) => RustLib.instance.api.crateApiTrackWidth(
  trackId: trackId,
  peerId: peerId,
  kind: kind,
);

/// Changes the [enabled][1] property of the [`MediaStreamTrack`] by its ID and
/// [`MediaType`].
///
/// [1]: https://w3.org/TR/mediacapture-streams#track-enabled
Future<void> setTrackEnabled({
  required String trackId,
  int? peerId,
  required MediaType kind,
  required bool enabled,
}) => RustLib.instance.api.crateApiSetTrackEnabled(
  trackId: trackId,
  peerId: peerId,
  kind: kind,
  enabled: enabled,
);

/// Clones the specified [`MediaStreamTrack`].
Future<MediaStreamTrack?> cloneTrack({
  required String trackId,
  int? peerId,
  required MediaType kind,
}) => RustLib.instance.api.crateApiCloneTrack(
  trackId: trackId,
  peerId: peerId,
  kind: kind,
);

/// Registers an observer to the [`MediaStreamTrack`] events.
Stream<TrackEvent> registerTrackObserver({
  int? peerId,
  required String trackId,
  required MediaType kind,
}) => RustLib.instance.api.crateApiRegisterTrackObserver(
  peerId: peerId,
  trackId: trackId,
  kind: kind,
);

/// Enables or disables audio level observing of the audio [`MediaStreamTrack`]
/// with the provided `track_id`.
Future<void> setAudioLevelObserverEnabled({
  required String trackId,
  int? peerId,
  required bool enabled,
}) => RustLib.instance.api.crateApiSetAudioLevelObserverEnabled(
  trackId: trackId,
  peerId: peerId,
  enabled: enabled,
);

/// Applies the provided [`AudioProcessingConstraints`] to specified local audio
/// track.
Future<void> updateAudioProcessing({
  required String trackId,
  required AudioProcessingConstraints conf,
}) => RustLib.instance.api.crateApiUpdateAudioProcessing(
  trackId: trackId,
  conf: conf,
);

/// Returns the current [`AudioProcessingConfig`] for the specified local audio
/// track.
Future<AudioProcessingConfig> getAudioProcessingConfig({
  required String trackId,
}) => RustLib.instance.api.crateApiGetAudioProcessingConfig(trackId: trackId);

/// Sets the provided `OnDeviceChangeCallback` as the callback to be called
/// whenever a set of available media devices changes.
///
/// Only one callback can be set at a time, so the previous one will be dropped,
/// if any.
Stream<void> setOnDeviceChanged() =>
    RustLib.instance.api.crateApiSetOnDeviceChanged();

/// Creates a new [`VideoSink`] attached to the specified video track.
///
/// `callback_ptr` argument should be a pointer to an [`UniquePtr`] pointing to
/// an [`sys::OnFrameCallback`].
///
/// [`UniquePtr`]: cxx::UniquePtr
/// [`VideoSink`]: crate::VideoSink
Stream<TextureEvent> createVideoSink({
  required PlatformInt64 sinkId,
  int? peerId,
  required String trackId,
  required PlatformInt64 callbackPtr,
  required PlatformInt64 textureId,
}) => RustLib.instance.api.crateApiCreateVideoSink(
  sinkId: sinkId,
  peerId: peerId,
  trackId: trackId,
  callbackPtr: callbackPtr,
  textureId: textureId,
);

/// Destroys a [`VideoSink`] by the provided ID.
///
/// [`VideoSink`]: crate::VideoSink
Future<void> disposeVideoSink({required PlatformInt64 sinkId}) =>
    RustLib.instance.api.crateApiDisposeVideoSink(sinkId: sinkId);

/// Nature and settings of the audio [`MediaStreamTrack`] returned by
/// [`Webrtc::get_media()`].
class AudioConstraints {
  /// Identifier of the device generating the content of the
  /// [`MediaStreamTrack`].
  ///
  /// First device will be chosen if an empty [`String`] is provided.
  final String? deviceId;

  /// Audio processing configuration constraints of the [`MediaStreamTrack`].
  final AudioProcessingConstraints processing;

  const AudioConstraints({this.deviceId, required this.processing});

  @override
  int get hashCode => deviceId.hashCode ^ processing.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is AudioConstraints &&
          runtimeType == other.runtimeType &&
          deviceId == other.deviceId &&
          processing == other.processing;
}

/// Audio processing configuration for some local audio [`MediaStreamTrack`].
class AudioProcessingConfig {
  /// Indicator whether the audio volume level should be automatically tuned
  /// to maintain a steady overall volume level.
  final bool autoGainControl;

  /// Indicator whether a high-pass filter should be enabled to eliminate
  /// low-frequency noise.
  final bool highPassFilter;

  /// Indicator whether noise suppression should be enabled to reduce
  /// background sounds.
  final bool noiseSuppression;

  /// Level of aggressiveness for noise suppression.
  final NoiseSuppressionLevel noiseSuppressionLevel;

  /// Indicator whether echo cancellation should be enabled to prevent
  /// feedback.
  final bool echoCancellation;

  const AudioProcessingConfig({
    required this.autoGainControl,
    required this.highPassFilter,
    required this.noiseSuppression,
    required this.noiseSuppressionLevel,
    required this.echoCancellation,
  });

  @override
  int get hashCode =>
      autoGainControl.hashCode ^
      highPassFilter.hashCode ^
      noiseSuppression.hashCode ^
      noiseSuppressionLevel.hashCode ^
      echoCancellation.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is AudioProcessingConfig &&
          runtimeType == other.runtimeType &&
          autoGainControl == other.autoGainControl &&
          highPassFilter == other.highPassFilter &&
          noiseSuppression == other.noiseSuppression &&
          noiseSuppressionLevel == other.noiseSuppressionLevel &&
          echoCancellation == other.echoCancellation;
}

/// Constraints of an [`AudioProcessingConfig`].
class AudioProcessingConstraints {
  /// Indicator whether the audio volume level should be automatically tuned
  /// to maintain a steady overall volume level.
  final bool? autoGainControl;

  /// Indicator whether a high-pass filter should be enabled to eliminate
  /// low-frequency noise.
  final bool? highPassFilter;

  /// Indicator whether noise suppression should be enabled to reduce
  /// background sounds.
  final bool? noiseSuppression;

  /// Level of aggressiveness for noise suppression.
  final NoiseSuppressionLevel? noiseSuppressionLevel;

  /// Indicator whether echo cancellation should be enabled to prevent
  /// feedback.
  final bool? echoCancellation;

  const AudioProcessingConstraints({
    this.autoGainControl,
    this.highPassFilter,
    this.noiseSuppression,
    this.noiseSuppressionLevel,
    this.echoCancellation,
  });

  static Future<AudioProcessingConstraints> default_() =>
      RustLib.instance.api.crateApiAudioProcessingConstraintsDefault();

  @override
  int get hashCode =>
      autoGainControl.hashCode ^
      highPassFilter.hashCode ^
      noiseSuppression.hashCode ^
      noiseSuppressionLevel.hashCode ^
      echoCancellation.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is AudioProcessingConstraints &&
          runtimeType == other.runtimeType &&
          autoGainControl == other.autoGainControl &&
          highPassFilter == other.highPassFilter &&
          noiseSuppression == other.noiseSuppression &&
          noiseSuppressionLevel == other.noiseSuppressionLevel &&
          echoCancellation == other.echoCancellation;
}

/// [RTCBundlePolicy][1] representation.
///
/// Affects which media tracks are negotiated if the remote endpoint is not
/// bundle-aware, and what ICE candidates are gathered. If the remote endpoint
/// is bundle-aware, all media tracks and data channels are bundled onto the
/// same transport.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtcbundlepolicy
enum BundlePolicy {
  /// [RTCBundlePolicy.balanced][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcbundlepolicy-balanced
  balanced,

  /// [RTCBundlePolicy.max-bundle][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcbundlepolicy-max-bundle
  maxBundle,

  /// [RTCBundlePolicy.max-compat][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcbundlepolicy-max-compat
  maxCompat,
}

@freezed
sealed class GetMediaError with _$GetMediaError {
  const GetMediaError._();

  /// Could not acquire audio track.
  const factory GetMediaError.audio(String field0) = GetMediaError_Audio;

  /// Could not acquire video track.
  const factory GetMediaError.video(String field0) = GetMediaError_Video;
}

@freezed
sealed class GetMediaResult with _$GetMediaResult {
  const GetMediaResult._();

  /// Requested media tracks.
  const factory GetMediaResult.ok(List<MediaStreamTrack> field0) =
      GetMediaResult_Ok;

  /// Failed to get requested media.
  const factory GetMediaResult.err(GetMediaError field0) = GetMediaResult_Err;
}

/// [RTCIceConnectionState][1] representation.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate
enum IceConnectionState {
  /// [RTCIceConnectionState.new][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-new
  new_,

  /// [RTCIceConnectionState.checking][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-checking
  checking,

  /// [RTCIceConnectionState.connected][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-connected
  connected,

  /// [RTCIceConnectionState.completed][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-completed
  completed,

  /// [RTCIceConnectionState.failed][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-failed
  failed,

  /// [RTCIceConnectionState.disconnected][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-disconnected
  disconnected,

  /// [RTCIceConnectionState.closed][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-closed
  closed,
}

/// [RTCIceGatheringState][1] representation.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtcicegatheringstate
enum IceGatheringState {
  /// [RTCIceGatheringState.new][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicegatheringstate-new
  new_,

  /// [RTCIceGatheringState.gathering][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicegatheringstate-gathering
  gathering,

  /// [RTCIceGatheringState.complete][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicegatheringstate-complete
  complete,
}

/// [RTCIceTransportPolicy][1] representation.
///
/// It defines an ICE candidate policy the [ICE Agent][2] uses to surface
/// the permitted candidates to the application. Only these candidates will
/// be used for connectivity checks.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtcicetransportpolicy
/// [2]: https://w3.org/TR/webrtc#dfn-ice-agent
enum IceTransportsType {
  /// [RTCIceTransportPolicy.all][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicetransportpolicy-all
  all,

  /// [RTCIceTransportPolicy.relay][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicetransportpolicy-relay
  relay,

  /// ICE Agent can't use `typ host` candidates when this value is specified.
  ///
  /// Non-spec-compliant variant.
  noHost,

  /// No ICE candidate offered.
  none,
}

/// [MediaStreamConstraints], used to instruct what sort of
/// [`MediaStreamTrack`]s to return by the [`Webrtc::get_media()`].
///
/// [1]: https://w3.org/TR/mediacapture-streams#dom-mediastreamconstraints
class MediaStreamConstraints {
  /// Specifies the nature and settings of the audio [`MediaStreamTrack`].
  final AudioConstraints? audio;

  /// Specifies the nature and settings of the video [`MediaStreamTrack`].
  final VideoConstraints? video;

  const MediaStreamConstraints({this.audio, this.video});

  @override
  int get hashCode => audio.hashCode ^ video.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is MediaStreamConstraints &&
          runtimeType == other.runtimeType &&
          audio == other.audio &&
          video == other.video;
}

/// Representation of a single media track within a [MediaStream].
///
/// Typically, these are audio or video tracks, but other track types may exist
/// as well.
///
/// [MediaStream]: https://w3.org/TR/mediacapture-streams#dom-mediastream
class MediaStreamTrack {
  /// Unique identifier (GUID) of this [`MediaStreamTrack`].
  final String id;

  /// Unique identifier of the [`PeerConnection`] from which this
  /// [`MediaStreamTrack`] was received.
  ///
  /// Always [`None`] for local [`MediaStreamTrack`]s.
  final int? peerId;

  /// Label identifying the track source, as in "internal microphone".
  final String deviceId;

  /// [`MediaType`] of this [`MediaStreamTrack`].
  final MediaType kind;

  /// Indicator whether this [`MediaStreamTrack`] is allowed to render the
  /// source stream.
  ///
  /// This can be used to intentionally mute a track.
  final bool enabled;

  const MediaStreamTrack({
    required this.id,
    this.peerId,
    required this.deviceId,
    required this.kind,
    required this.enabled,
  });

  @override
  int get hashCode =>
      id.hashCode ^
      peerId.hashCode ^
      deviceId.hashCode ^
      kind.hashCode ^
      enabled.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is MediaStreamTrack &&
          runtimeType == other.runtimeType &&
          id == other.id &&
          peerId == other.peerId &&
          deviceId == other.deviceId &&
          kind == other.kind &&
          enabled == other.enabled;
}

/// Possible media types of a [`MediaStreamTrack`].
enum MediaType {
  /// Audio [`MediaStreamTrack`].
  audio,

  /// Video [`MediaStreamTrack`].
  video,
}

/// [`AudioProcessingConfig`] noise suppression aggressiveness.
enum NoiseSuppressionLevel {
  /// Minimal noise suppression.
  low,

  /// Moderate level of suppression.
  moderate,

  /// Aggressive noise suppression.
  high,

  /// Maximum suppression.
  veryHigh,
}

@freezed
sealed class PeerConnectionEvent with _$PeerConnectionEvent {
  const PeerConnectionEvent._();

  /// [`PeerConnection`] has been created.
  const factory PeerConnectionEvent.peerCreated({
    /// Rust side [`PeerConnection`].
    required ArcPeerConnection peer,
  }) = PeerConnectionEvent_PeerCreated;

  /// [RTCIceCandidate][1] has been discovered.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
  const factory PeerConnectionEvent.iceCandidate({
    /// Media stream "identification-tag" defined in [RFC 5888] for the
    /// media component the discovered [RTCIceCandidate][1] is associated
    /// with.
    ///
    /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
    /// [RFC 5888]: https://tools.ietf.org/html/rfc5888
    required String sdpMid,

    /// Index (starting at zero) of the media description in the SDP this
    /// [RTCIceCandidate][1] is associated with.
    ///
    /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
    required int sdpMlineIndex,

    /// Candidate-attribute as defined in Section 15.1 of [RFC 5245].
    ///
    /// If this [RTCIceCandidate][1] represents an end-of-candidates
    /// indication or a peer reflexive remote candidate, candidate is an
    /// empty string.
    ///
    /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
    /// [RFC 5245]: https://tools.ietf.org/html/rfc5245
    required String candidate,
  }) = PeerConnectionEvent_IceCandidate;

  /// [`PeerConnection`]'s ICE gathering state has changed.
  const factory PeerConnectionEvent.iceGatheringStateChange(
    IceGatheringState field0,
  ) = PeerConnectionEvent_IceGatheringStateChange;

  /// Failure occurred when gathering [RTCIceCandidate][1].
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
  const factory PeerConnectionEvent.iceCandidateError({
    /// Local IP address used to communicate with the STUN or TURN server.
    required String address,

    /// Port used to communicate with the STUN or TURN server.
    required int port,

    /// STUN or TURN URL identifying the STUN or TURN server for which the
    /// failure occurred.
    required String url,

    /// Numeric STUN error code returned by the STUN or TURN server
    /// [`STUN-PARAMETERS`][1].
    ///
    /// If no host candidate can reach the server, it will be set to the
    /// value `701` which is outside the STUN error code range.
    ///
    /// [1]: https://tinyurl.com/stun-parameters-6
    required int errorCode,

    /// STUN reason text returned by the STUN or TURN server
    /// [`STUN-PARAMETERS`][1].
    ///
    /// If the server could not be reached, it will be set to an
    /// implementation-specific value providing details about the error.
    ///
    /// [1]: https://tinyurl.com/stun-parameters-6
    required String errorText,
  }) = PeerConnectionEvent_IceCandidateError;

  /// Negotiation or renegotiation of the [`PeerConnection`] needs to be
  /// performed.
  const factory PeerConnectionEvent.negotiationNeeded() =
      PeerConnectionEvent_NegotiationNeeded;

  /// [`PeerConnection`]'s [`SignalingState`] has been changed.
  const factory PeerConnectionEvent.signallingChange(SignalingState field0) =
      PeerConnectionEvent_SignallingChange;

  /// [`PeerConnection`]'s [`IceConnectionState`] has been changed.
  const factory PeerConnectionEvent.iceConnectionStateChange(
    IceConnectionState field0,
  ) = PeerConnectionEvent_IceConnectionStateChange;

  /// [`PeerConnection`]'s [`PeerConnectionState`] has been changed.
  const factory PeerConnectionEvent.connectionStateChange(
    PeerConnectionState field0,
  ) = PeerConnectionEvent_ConnectionStateChange;

  /// New incoming media has been negotiated.
  const factory PeerConnectionEvent.track(RtcTrackEvent field0) =
      PeerConnectionEvent_Track;
}

/// Indicator of the current state of a [`PeerConnection`].
enum PeerConnectionState {
  /// At least one of the connection's ICE transports is in the new state,
  /// and none of them are in one of the following states: `connecting`,
  /// `checking`, `failed`, `disconnected`, or all of the connection's
  /// transports are in the `closed` state.
  new_,

  /// One or more of the ICE transports are currently in the process of
  /// establishing a connection. That is, their [`IceConnectionState`] is
  /// either [`IceConnectionState::Checking`] or
  /// [`IceConnectionState::Connected`], and no transports are in the
  /// `failed` state.
  connecting,

  /// Every ICE transport used by the connection is either in use (state
  /// `connected` or `completed`) or is closed (state `closed`). In addition,
  /// at least one transport is either `connected` or `completed`.
  connected,

  /// At least one of the ICE transports for the connection is in the
  /// `disconnected` state and none of the other transports are in the state
  /// `failed`, `connecting` or `checking`.
  disconnected,

  /// One or more of the ICE transports on the connection is in the `failed`
  /// state.
  failed,

  /// Peer connection is closed.
  closed,
}

/// [`PeerConnection`]'s configuration.
class RtcConfiguration {
  /// [iceTransportPolicy][1] configuration.
  ///
  /// Indicates which candidates the [ICE Agent][2] is allowed to use.
  ///
  /// [1]: https://tinyurl.com/icetransportpolicy
  /// [2]: https://w3.org/TR/webrtc#dfn-ice-agent
  final IceTransportsType iceTransportPolicy;

  /// [bundlePolicy][1] configuration.
  ///
  /// Indicates which media-bundling policy to use when gathering ICE
  /// candidates.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcconfiguration-bundlepolicy
  final BundlePolicy bundlePolicy;

  /// [iceServers][1] configuration.
  ///
  /// An array of objects describing servers available to be used by ICE,
  /// such as STUN and TURN servers.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcconfiguration-iceservers
  final List<RtcIceServer> iceServers;

  const RtcConfiguration({
    required this.iceTransportPolicy,
    required this.bundlePolicy,
    required this.iceServers,
  });

  @override
  int get hashCode =>
      iceTransportPolicy.hashCode ^ bundlePolicy.hashCode ^ iceServers.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcConfiguration &&
          runtimeType == other.runtimeType &&
          iceTransportPolicy == other.iceTransportPolicy &&
          bundlePolicy == other.bundlePolicy &&
          iceServers == other.iceServers;
}

/// Description of STUN and TURN servers that can be used by an [ICE Agent][1]
/// to establish a connection with a peer.
///
/// [1]: https://w3.org/TR/webrtc#dfn-ice-agent
class RtcIceServer {
  /// STUN or TURN URI(s).
  final List<String> urls;

  /// If this [`RtcIceServer`] object represents a TURN server, then this
  /// attribute specifies the [username][1] to use with that TURN server.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceserver-username
  final String username;

  /// If this [`RtcIceServer`] object represents a TURN server, then this
  /// attribute specifies the [credential][1] to use with that TURN
  /// server.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceserver-credential
  final String credential;

  const RtcIceServer({
    required this.urls,
    required this.username,
    required this.credential,
  });

  @override
  int get hashCode => urls.hashCode ^ username.hashCode ^ credential.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcIceServer &&
          runtimeType == other.runtimeType &&
          urls == other.urls &&
          username == other.username &&
          credential == other.credential;
}

/// Representation of [RTCRtpEncodingParameters][0].
///
/// [0]: https://w3.org/TR/webrtc#rtcrtpencodingparameters
class RtcRtpEncodingParameters {
  /// [RTP stream ID (RID)][0] to be sent using the RID header extension.
  ///
  /// [0]: https://w3.org/TR/webrtc#dom-rtcrtpcodingparameters-rid
  final String rid;

  /// Indicator whether the described [`RtcRtpEncodingParameters`] are
  /// currently actively being used.
  final bool active;

  /// Maximum number of bits per second to allow for these
  /// [`RtcRtpEncodingParameters`].
  final int? maxBitrate;

  /// Maximum number of frames per second to allow for these
  /// [`RtcRtpEncodingParameters`].
  final double? maxFramerate;

  /// Factor for scaling down the video with these
  /// [`RtcRtpEncodingParameters`].
  final double? scaleResolutionDownBy;

  /// Scalability mode describing layers within the media stream.
  final String? scalabilityMode;

  const RtcRtpEncodingParameters({
    required this.rid,
    required this.active,
    this.maxBitrate,
    this.maxFramerate,
    this.scaleResolutionDownBy,
    this.scalabilityMode,
  });

  @override
  int get hashCode =>
      rid.hashCode ^
      active.hashCode ^
      maxBitrate.hashCode ^
      maxFramerate.hashCode ^
      scaleResolutionDownBy.hashCode ^
      scalabilityMode.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcRtpEncodingParameters &&
          runtimeType == other.runtimeType &&
          rid == other.rid &&
          active == other.active &&
          maxBitrate == other.maxBitrate &&
          maxFramerate == other.maxFramerate &&
          scaleResolutionDownBy == other.scaleResolutionDownBy &&
          scalabilityMode == other.scalabilityMode;
}

/// Representation of [RTCRtpSendParameters][0].
///
/// [0]: https://w3.org/TR/webrtc#dom-rtcrtpsendparameters
class RtcRtpSendParameters {
  /// Sequence containing parameters for sending [RTP] encodings of media.
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  final List<(RtcRtpEncodingParameters, ArcRtpEncodingParameters)> encodings;

  /// Reference to the Rust side [`RtpParameters`].
  final ArcRtpParameters inner;

  const RtcRtpSendParameters({required this.encodings, required this.inner});

  @override
  int get hashCode => encodings.hashCode ^ inner.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcRtpSendParameters &&
          runtimeType == other.runtimeType &&
          encodings == other.encodings &&
          inner == other.inner;
}

/// Representation of a permanent pair of an [RTCRtpSender] and an
/// [RTCRtpReceiver], along with some shared state.
///
/// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
/// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
class RtcRtpTransceiver {
  /// [`PeerConnection`] that this [`RtcRtpTransceiver`] belongs to.
  final ArcPeerConnection peer;

  /// Rust side [`RtpTransceiver`].
  final ArcRtpTransceiver transceiver;

  /// [Negotiated media ID (mid)][1] which the local and remote peers have
  /// agreed upon to uniquely identify the [MediaStream]'s pairing of sender
  /// and receiver.
  ///
  /// [MediaStream]: https://w3.org/TR/mediacapture-streams#dom-mediastream
  /// [1]: https://w3.org/TR/webrtc#dfn-media-stream-identification-tag
  final String? mid;

  /// Preferred [`direction`][1] of this [`RtcRtpTransceiver`].
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver-direction
  final RtpTransceiverDirection direction;

  const RtcRtpTransceiver({
    required this.peer,
    required this.transceiver,
    this.mid,
    required this.direction,
  });

  @override
  int get hashCode =>
      peer.hashCode ^ transceiver.hashCode ^ mid.hashCode ^ direction.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcRtpTransceiver &&
          runtimeType == other.runtimeType &&
          peer == other.peer &&
          transceiver == other.transceiver &&
          mid == other.mid &&
          direction == other.direction;
}

/// [RTCSessionDescription] representation.
///
/// [RTCSessionDescription]: https://w3.org/TR/webrtc#dom-rtcsessiondescription
class RtcSessionDescription {
  /// String representation of the SDP.
  final String sdp;

  /// Type of this [`RtcSessionDescription`].
  final SdpType kind;

  const RtcSessionDescription({required this.sdp, required this.kind});

  @override
  int get hashCode => sdp.hashCode ^ kind.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcSessionDescription &&
          runtimeType == other.runtimeType &&
          sdp == other.sdp &&
          kind == other.kind;
}

/// Representation of a track event, sent when a new [`MediaStreamTrack`] is
/// added to an [`RtcRtpTransceiver`] as part of a [`PeerConnection`].
class RtcTrackEvent {
  /// [`MediaStreamTrack`] associated with the [RTCRtpReceiver] identified
  /// by the receiver.
  ///
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  final MediaStreamTrack track;

  /// [`RtcRtpTransceiver`] object associated with the event.
  final RtcRtpTransceiver transceiver;

  const RtcTrackEvent({required this.track, required this.transceiver});

  @override
  int get hashCode => track.hashCode ^ transceiver.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcTrackEvent &&
          runtimeType == other.runtimeType &&
          track == other.track &&
          transceiver == other.transceiver;
}

/// [RTCP] feedback message intended to enable congestion control for
/// interactive real-time traffic using [RTP].
///
/// [RTCP]: https://en.wikipedia.org/wiki/RTP_Control_Protocol
/// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
class RtcpFeedback {
  /// Message type of this [`RtcpFeedback`].
  final RtcpFeedbackMessageType? messageType;

  /// Kind of this [`RtcpFeedback`].
  final RtcpFeedbackType kind;

  const RtcpFeedback({this.messageType, required this.kind});

  @override
  int get hashCode => messageType.hashCode ^ kind.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcpFeedback &&
          runtimeType == other.runtimeType &&
          messageType == other.messageType &&
          kind == other.kind;
}

/// Possible message types of an [`RtcpFeedback`], when is type is
/// [`RtcpFeedbackType::Nack`] or [`RtcpFeedbackType::Ccm`].
enum RtcpFeedbackMessageType {
  /// Equivalent to `{ type: "nack", parameter: undefined }` in ORTC.
  genericNack,

  /// Usable with [`RtcpFeedbackType::Nack`].
  pli,

  /// Usable with [`RtcpFeedbackType::Ccm`].
  fir,
}

/// Possible types of an [`RtcpFeedback`].
enum RtcpFeedbackType {
  /// Codec control messages.
  ccm,

  /// Loss notification feedback.
  lntf,

  /// Negative acknowledgemen.
  nack,

  /// Receiver estimated maximum bitrate.
  remb,

  /// Transport wide congestion control.
  transportCc,
}

/// Representation of the static capabilities of an endpoint.
///
/// Applications can use these capabilities to construct [`RtpParameters`].
class RtpCapabilities {
  /// Supported codecs.
  final List<RtpCodecCapability> codecs;

  /// Supported [RTP] header extensions.
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  final List<RtpHeaderExtensionCapability> headerExtensions;

  const RtpCapabilities({required this.codecs, required this.headerExtensions});

  @override
  int get hashCode => codecs.hashCode ^ headerExtensions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtpCapabilities &&
          runtimeType == other.runtimeType &&
          codecs == other.codecs &&
          headerExtensions == other.headerExtensions;
}

/// Representation of static capabilities of an endpoint's implementation of a
/// codec.
class RtpCodecCapability {
  /// Default payload type for the codec.
  ///
  /// Mainly needed for codecs that have statically assigned payload types.
  final int? preferredPayloadType;

  /// List of [`ScalabilityMode`]s supported by the video codec.
  final List<ScalabilityMode> scalabilityModes;

  /// Built [MIME "type/subtype"][0] string from `name` and `kind`.
  ///
  /// [0]: https://en.wikipedia.org/wiki/Media_type
  final String mimeType;

  /// Used to identify the codec. Equivalent to [MIME subtype][0].
  ///
  /// [0]: https://en.wikipedia.org/wiki/Media_type#Subtypes
  final String name;

  /// [`MediaType`] of this codec. Equivalent to [MIME] top-level type.
  ///
  /// [MIME]: https://en.wikipedia.org/wiki/Media_type
  final MediaType kind;

  /// If [`None`], the implementation default is used.
  final int? clockRate;

  /// Number of audio channels used.
  ///
  /// [`None`] for video codecs.
  ///
  /// If [`None`] for audio, the implementation default is used.
  final int? numChannels;

  /// Codec-specific parameters that must be signaled to the remote party.
  ///
  /// Corresponds to `a=fmtp` parameters in [SDP].
  ///
  /// Contrary to ORTC, these parameters are named using all lowercase
  /// strings. This helps make the mapping to [SDP] simpler, if an application
  /// is using [SDP]. Boolean values are represented by the string "1".
  ///
  /// [SDP]: https://en.wikipedia.org/wiki/Session_Description_Protocol
  final List<(String, String)> parameters;

  /// Feedback mechanisms to be used for this codec.
  final List<RtcpFeedback> feedback;

  const RtpCodecCapability({
    this.preferredPayloadType,
    required this.scalabilityModes,
    required this.mimeType,
    required this.name,
    required this.kind,
    this.clockRate,
    this.numChannels,
    required this.parameters,
    required this.feedback,
  });

  @override
  int get hashCode =>
      preferredPayloadType.hashCode ^
      scalabilityModes.hashCode ^
      mimeType.hashCode ^
      name.hashCode ^
      kind.hashCode ^
      clockRate.hashCode ^
      numChannels.hashCode ^
      parameters.hashCode ^
      feedback.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtpCodecCapability &&
          runtimeType == other.runtimeType &&
          preferredPayloadType == other.preferredPayloadType &&
          scalabilityModes == other.scalabilityModes &&
          mimeType == other.mimeType &&
          name == other.name &&
          kind == other.kind &&
          clockRate == other.clockRate &&
          numChannels == other.numChannels &&
          parameters == other.parameters &&
          feedback == other.feedback;
}

/// Representation of capabilities/preferences of an implementation for a header
/// extension of [`RtpCapabilities`].
class RtpHeaderExtensionCapability {
  /// [URI] of this extension, as defined in [RFC 8285].
  ///
  /// [RFC 8285]: https://tools.ietf.org/html/rfc8285
  /// [URI]: https://en.wikipedia.org/wiki/Uniform_Resource_Identifier
  final String uri;

  /// Preferred value of ID that goes in the packet.
  final int? preferredId;

  /// If [`true`], it's preferred that the value in the header is encrypted.
  final bool preferredEncrypted;

  /// Direction of the extension.
  ///
  /// [`RtpTransceiverDirection::Stopped`] value is only used with
  /// `RtpTransceiverInterface::SetHeaderExtensionsToNegotiate()` and
  /// `SetHeaderExtensionsToNegotiate()`.
  final RtpTransceiverDirection direction;

  const RtpHeaderExtensionCapability({
    required this.uri,
    this.preferredId,
    required this.preferredEncrypted,
    required this.direction,
  });

  @override
  int get hashCode =>
      uri.hashCode ^
      preferredId.hashCode ^
      preferredEncrypted.hashCode ^
      direction.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtpHeaderExtensionCapability &&
          runtimeType == other.runtimeType &&
          uri == other.uri &&
          preferredId == other.preferredId &&
          preferredEncrypted == other.preferredEncrypted &&
          direction == other.direction;
}

/// [RTCRtpTransceiverDirection][1] representation.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtcrtptransceiverdirection
enum RtpTransceiverDirection {
  /// The [RTCRtpTransceiver]'s [RTCRtpSender] will offer to send RTP, and
  /// will send RTP if the remote peer accepts. The [RTCRtpTransceiver]'s
  /// [RTCRtpReceiver] will offer to receive RTP, and will receive RTP if the
  /// remote peer accepts.
  ///
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpTransceiver]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver
  sendRecv,

  /// The [RTCRtpTransceiver]'s [RTCRtpSender] will offer to send RTP, and
  /// will send RTP if the remote peer accepts. The [RTCRtpTransceiver]'s
  /// [RTCRtpReceiver] will not offer to receive RTP, and will not receive
  /// RTP.
  ///
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpTransceiver]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver
  sendOnly,

  /// The [RTCRtpTransceiver]'s [RTCRtpSender] will not offer to send RTP,
  /// and will not send RTP. The [RTCRtpTransceiver]'s [RTCRtpReceiver] will
  /// offer to receive RTP, and will receive RTP if the remote peer accepts.
  ///
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpTransceiver]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver
  recvOnly,

  /// The [RTCRtpTransceiver]'s [RTCRtpSender] will not offer to send RTP,
  /// and will not send RTP. The [RTCRtpTransceiver]'s [RTCRtpReceiver] will
  /// not offer to receive RTP, and will not receive RTP.
  ///
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpTransceiver]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver
  inactive,

  /// The [RTCRtpTransceiver] will neither send nor receive RTP. It will
  /// generate a zero port in the offer. In answers, its [RTCRtpSender] will
  /// not offer to send RTP, and its [RTCRtpReceiver] will not offer to
  /// receive RTP. This is a terminal state.
  ///
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpTransceiver]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver
  stopped,
}

/// Representation of an [RTCRtpTransceiverInit][0].
///
/// [0]: https://w3.org/TR/webrtc#dom-rtcrtptransceiverinit
class RtpTransceiverInit {
  /// Direction of the [RTCRtpTransceiver].
  ///
  /// [RTCRtpTransceiver]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver
  final RtpTransceiverDirection direction;

  /// Sequence containing parameters for sending [RTP] encodings of media.
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  final List<RtcRtpEncodingParameters> sendEncodings;

  const RtpTransceiverInit({
    required this.direction,
    required this.sendEncodings,
  });

  @override
  int get hashCode => direction.hashCode ^ sendEncodings.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtpTransceiverInit &&
          runtimeType == other.runtimeType &&
          direction == other.direction &&
          sendEncodings == other.sendEncodings;
}

/// [ScalabilityMode][0] representation.
///
/// [0]: https://tinyurl.com/35ae3mbe
enum ScalabilityMode {
  /// [ScalabilityMode.L1T1][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L1T1*
  l1T1,

  /// [ScalabilityMode.L1T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L1T2*
  l1T2,

  /// [ScalabilityMode.L1T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L1T3*
  l1T3,

  /// [ScalabilityMode.L2T1][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T1*
  l2T1,

  /// [ScalabilityMode.L2T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T1*
  l2T1H,

  /// [ScalabilityMode.L2T1_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T1_KEY*
  l2T1Key,

  /// [ScalabilityMode.L2T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T2h*
  l2T2,

  /// [ScalabilityMode.L2T2h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T2*
  l2T2H,

  /// [ScalabilityMode.L2T2_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T2_KEY*
  l2T2Key,

  /// [ScalabilityMode.L2T2_KEY_SHIFT][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T2_KEY_SHIFT*
  l2T2KeyShift,

  /// [ScalabilityMode.L2T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T3*
  l2T3,

  /// [ScalabilityMode.L2T3h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T3*
  l2T3H,

  /// [ScalabilityMode.L2T3_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T3_KEY*
  l2T3Key,

  /// [ScalabilityMode.L3T1][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T1*
  l3T1,

  /// [ScalabilityMode.L3T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T1*
  l3T1H,

  /// [ScalabilityMode.L3T1_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T1_KEY*
  l3T1Key,

  /// [ScalabilityMode.L3T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T2h*
  l3T2,

  /// [ScalabilityMode.L3T2h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T2*
  l3T2H,

  /// [ScalabilityMode.L3T2_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T2_KEY*
  l3T2Key,

  /// [ScalabilityMode.kL3T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kL3T3*
  l3T3,

  /// [ScalabilityMode.kL3T3h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kL3T3*
  l3T3H,

  /// [ScalabilityMode.kL3T3_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T3_KEY*
  l3T3Key,

  /// [ScalabilityMode.kS2T1][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kS2T1*
  s2T1,

  /// [ScalabilityMode.kS2T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kS2T1*
  s2T1H,

  /// [ScalabilityMode.kS2T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kS2T2*
  s2T2,

  /// [ScalabilityMode.kS2T2h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kS2T2*
  s2T2H,

  /// [ScalabilityMode.S2T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S2T3h*
  s2T3,

  /// [ScalabilityMode.S2T3h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S2T3*
  s2T3H,

  /// [ScalabilityMode.S3T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T1*
  s3T1,

  /// [ScalabilityMode.S3T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T1*
  s3T1H,

  /// [ScalabilityMode.S3T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T2*
  s3T2,

  /// [ScalabilityMode.S3T2h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T2*
  s3T2H,

  /// [ScalabilityMode.S3T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T3*
  s3T3,

  /// [ScalabilityMode.S3T3h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T3*
  s3T3H,
}

/// [RTCSdpType] representation.
///
/// [RTCSdpType]: https://w3.org/TR/webrtc#dom-rtcsdptype
enum SdpType {
  /// [RTCSdpType.offer][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsdptype-offer
  offer,

  /// [RTCSdpType.pranswer][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsdptype-pranswer
  prAnswer,

  /// [RTCSdpType.answer][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsdptype-answer
  answer,

  /// [RTCSdpType.rollback][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsdptype-rollback
  rollback,
}

/// [RTCSignalingState] representation.
///
/// [RTCSignalingState]: https://w3.org/TR/webrtc#state-definitions
enum SignalingState {
  /// [RTCSignalingState.stable][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsignalingstate-stable
  stable,

  /// [RTCSignalingState.have-local-offer][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsignalingstate-have-local-offer
  haveLocalOffer,

  /// [RTCSignalingState.have-local-pranswer][1] representation.
  ///
  /// [1]: https://tinyurl.com/have-local-pranswer
  haveLocalPrAnswer,

  /// [RTCSignalingState.have-remote-offer][1] representation.
  ///
  /// [1]: https://tinyurl.com/have-remote-offer
  haveRemoteOffer,

  /// [RTCSignalingState.have-remote-pranswer][1] representation.
  ///
  /// [1]: https://tinyurl.com/have-remote-pranswer
  haveRemotePrAnswer,

  /// [RTCSignalingState.closed][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsignalingstate-closed
  closed,
}

@freezed
sealed class TrackEvent with _$TrackEvent {
  const TrackEvent._();

  /// Ended event of the [`MediaStreamTrack`] interface is fired when playback
  /// or streaming has stopped because the end of the media was reached or
  /// because no further data is available.
  const factory TrackEvent.ended() = TrackEvent_Ended;

  /// Event indicating an audio level change in the [`MediaStreamTrack`].
  const factory TrackEvent.audioLevelUpdated(int field0) =
      TrackEvent_AudioLevelUpdated;

  /// Event indicating that the [`MediaStreamTrack`] has completely
  /// initialized and can be used on Flutter side.
  const factory TrackEvent.trackCreated() = TrackEvent_TrackCreated;
}

/// Indicator of the current [MediaStreamTrackState][0] of a
/// [`MediaStreamTrack`].
///
/// [0]: https://w3.org/TR/mediacapture-streams#dom-mediastreamtrackstate
enum TrackState {
  /// [MediaStreamTrackState.live][0] representation.
  ///
  /// [0]: https://tinyurl.com/w3mcs#idl-def-MediaStreamTrackState.live
  live,

  /// [MediaStreamTrackState.ended][0] representation.
  ///
  /// [0]: https://tinyurl.com/w3mcs#idl-def-MediaStreamTrackState.ended
  ended,
}

/// Supported video codecs.
enum VideoCodec {
  /// [AV1] AOMedia Video 1.
  ///
  /// [AV1]: https://en.wikipedia.org/wiki/AV1
  av1,

  /// [H.264] Advanced Video Coding (AVC).
  ///
  /// [H.264]: https://en.wikipedia.org/wiki/Advanced_Video_Coding
  h264,

  /// [H.265] High Efficiency Video Coding (HEVC).
  ///
  /// [H.265]: https://en.wikipedia.org/wiki/High_Efficiency_Video_Coding
  h265,

  /// [VP8] codec.
  ///
  /// [VP8]: https://en.wikipedia.org/wiki/VP8
  vp8,

  /// [VP9] codec.
  ///
  /// [VP9]: https://en.wikipedia.org/wiki/VP9
  vp9,
}

/// [`VideoCodec`] info for encoding/decoding.
class VideoCodecInfo {
  /// Indicator whether hardware acceleration should be used.
  final bool isHardwareAccelerated;

  /// [`VideoCodec`] to be used for encoding/decoding.
  final VideoCodec codec;

  const VideoCodecInfo({
    required this.isHardwareAccelerated,
    required this.codec,
  });

  @override
  int get hashCode => isHardwareAccelerated.hashCode ^ codec.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is VideoCodecInfo &&
          runtimeType == other.runtimeType &&
          isHardwareAccelerated == other.isHardwareAccelerated &&
          codec == other.codec;
}

/// Nature and settings of the video [`MediaStreamTrack`] returned by
/// [`Webrtc::get_media()`].
class VideoConstraints {
  /// Identifier of the device generating the content of the
  /// [`MediaStreamTrack`].
  ///
  /// The first device will be chosen if an empty [`String`] is provided.
  final String? deviceId;

  /// Width in pixels.
  final int width;

  /// Height in pixels.
  final int height;

  /// Exact frame rate (frames per second).
  final int frameRate;

  /// Indicator whether the request video track should be acquired via screen
  /// capturing.
  final bool isDisplay;

  const VideoConstraints({
    this.deviceId,
    required this.width,
    required this.height,
    required this.frameRate,
    required this.isDisplay,
  });

  @override
  int get hashCode =>
      deviceId.hashCode ^
      width.hashCode ^
      height.hashCode ^
      frameRate.hashCode ^
      isDisplay.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is VideoConstraints &&
          runtimeType == other.runtimeType &&
          deviceId == other.deviceId &&
          width == other.width &&
          height == other.height &&
          frameRate == other.frameRate &&
          isDisplay == other.isDisplay;
}

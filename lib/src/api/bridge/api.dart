// This file is automatically generated, so please do not edit it.
// @generated by `flutter_rust_bridge`@ 2.9.0.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';
import 'package:freezed_annotation/freezed_annotation.dart' hide protected;

import 'frb_generated.dart';
import 'lib.dart';
import 'renderer.dart';

part 'api.freezed.dart';

// These types are ignored because they are neither used by any `pub` functions nor (for structs and enums) marked `#[frb(unignore)]`: `TrackKind`
// These function are ignored because they are on traits that is not defined in current crate (put an empty `#[frb]` on it to unignore): `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `hash`, `hash`, `hash`

/// Returns all [`VideoCodecInfo`]s of the supported video encoders.
Future<List<VideoCodecInfo>> videoEncoders() =>
    RustLib.instance.api.crateApiVideoEncoders();

/// Returns all [`VideoCodecInfo`]s of the supported video decoders.
Future<List<VideoCodecInfo>> videoDecoders() =>
    RustLib.instance.api.crateApiVideoDecoders();

/// Configures media acquisition to use fake devices instead of actual camera
/// and microphone.
Future<void> enableFakeMedia() =>
    RustLib.instance.api.crateApiEnableFakeMedia();

/// Indicates whether application is configured to use fake media devices.
Future<bool> isFakeMedia() => RustLib.instance.api.crateApiIsFakeMedia();

/// Returns a list of all available media input and output devices, such as
/// microphones, cameras, headsets, and so forth.
Future<List<MediaDeviceInfo>> enumerateDevices() =>
    RustLib.instance.api.crateApiEnumerateDevices();

/// Returns a list of all available displays that can be used for screen
/// capturing.
Future<List<MediaDisplayInfo>> enumerateDisplays() =>
    RustLib.instance.api.crateApiEnumerateDisplays();

/// Creates a new [`PeerConnection`] and returns its ID.
Stream<PeerConnectionEvent> createPeerConnection({
  required RtcConfiguration configuration,
}) => RustLib.instance.api.crateApiCreatePeerConnection(
  configuration: configuration,
);

/// Initiates the creation of an SDP offer for the purpose of starting a new
/// WebRTC connection to a remote peer.
Future<RtcSessionDescription> createOffer({
  required ArcPeerConnection peer,
  required bool voiceActivityDetection,
  required bool iceRestart,
  required bool useRtpMux,
}) => RustLib.instance.api.crateApiCreateOffer(
  peer: peer,
  voiceActivityDetection: voiceActivityDetection,
  iceRestart: iceRestart,
  useRtpMux: useRtpMux,
);

/// Creates an SDP answer to an offer received from a remote peer during an
/// offer/answer negotiation of a WebRTC connection.
Future<RtcSessionDescription> createAnswer({
  required ArcPeerConnection peer,
  required bool voiceActivityDetection,
  required bool iceRestart,
  required bool useRtpMux,
}) => RustLib.instance.api.crateApiCreateAnswer(
  peer: peer,
  voiceActivityDetection: voiceActivityDetection,
  iceRestart: iceRestart,
  useRtpMux: useRtpMux,
);

/// Changes the local description associated with the connection.
Future<void> setLocalDescription({
  required ArcPeerConnection peer,
  required SdpType kind,
  required String sdp,
}) => RustLib.instance.api.crateApiSetLocalDescription(
  peer: peer,
  kind: kind,
  sdp: sdp,
);

/// Sets the specified session description as the remote peer's current offer or
/// answer.
Future<void> setRemoteDescription({
  required ArcPeerConnection peer,
  required SdpType kind,
  required String sdp,
}) => RustLib.instance.api.crateApiSetRemoteDescription(
  peer: peer,
  kind: kind,
  sdp: sdp,
);

/// Creates a new [`RtcRtpTransceiver`] and adds it to the set of transceivers
/// of the specified [`PeerConnection`].
Future<RtcRtpTransceiver> addTransceiver({
  required ArcPeerConnection peer,
  required MediaType mediaType,
  required RtpTransceiverInit init,
}) => RustLib.instance.api.crateApiAddTransceiver(
  peer: peer,
  mediaType: mediaType,
  init: init,
);

/// Returns a sequence of [`RtcRtpTransceiver`] objects representing the RTP
/// transceivers currently attached to the specified [`PeerConnection`].
Future<List<RtcRtpTransceiver>> getTransceivers({
  required ArcPeerConnection peer,
}) => RustLib.instance.api.crateApiGetTransceivers(peer: peer);

/// Changes the preferred `direction` of the specified [`RtcRtpTransceiver`].
Future<void> setTransceiverDirection({
  required ArcRtpTransceiver transceiver,
  required RtpTransceiverDirection direction,
}) => RustLib.instance.api.crateApiSetTransceiverDirection(
  transceiver: transceiver,
  direction: direction,
);

/// Changes the receive direction of the specified [`RtcRtpTransceiver`].
Future<void> setTransceiverRecv({
  required ArcRtpTransceiver transceiver,
  required bool recv,
}) => RustLib.instance.api.crateApiSetTransceiverRecv(
  transceiver: transceiver,
  recv: recv,
);

/// Changes the send direction of the specified [`RtcRtpTransceiver`].
Future<void> setTransceiverSend({
  required ArcRtpTransceiver transceiver,
  required bool send,
}) => RustLib.instance.api.crateApiSetTransceiverSend(
  transceiver: transceiver,
  send: send,
);

/// Returns the [negotiated media ID (mid)][1] of the specified
/// [`RtcRtpTransceiver`].
///
/// [1]: https://w3.org/TR/webrtc#dfn-media-stream-identification-tag
Future<String?> getTransceiverMid({required ArcRtpTransceiver transceiver}) =>
    RustLib.instance.api.crateApiGetTransceiverMid(transceiver: transceiver);

/// Returns the preferred direction of the specified [`RtcRtpTransceiver`].
Future<RtpTransceiverDirection> getTransceiverDirection({
  required ArcRtpTransceiver transceiver,
}) => RustLib.instance.api.crateApiGetTransceiverDirection(
  transceiver: transceiver,
);

/// Returns [`RtcStats`] of the [`PeerConnection`] by its ID.
Future<List<RtcStats>> getPeerStats({required ArcPeerConnection peer}) =>
    RustLib.instance.api.crateApiGetPeerStats(peer: peer);

/// Irreversibly marks the specified [`RtcRtpTransceiver`] as stopping, unless
/// it's already stopped.
///
/// This will immediately cause the transceiver's sender to no longer send, and
/// its receiver to no longer receive.
Future<void> stopTransceiver({required ArcRtpTransceiver transceiver}) =>
    RustLib.instance.api.crateApiStopTransceiver(transceiver: transceiver);

/// Changes the preferred [`RtpTransceiver`] codecs to the provided
/// [`Vec`]`<`[`RtpCodecCapability`]`>`.
Future<void> setCodecPreferences({
  required ArcRtpTransceiver transceiver,
  required List<RtpCodecCapability> codecs,
}) => RustLib.instance.api.crateApiSetCodecPreferences(
  transceiver: transceiver,
  codecs: codecs,
);

/// Replaces the specified [`AudioTrack`] (or [`VideoTrack`]) on the
/// [`sys::RtpTransceiverInterface`]'s `sender`.
///
/// [`AudioTrack`]: crate::AudioTrack
/// [`VideoTrack`]: crate::VideoTrack
Future<void> senderReplaceTrack({
  required ArcPeerConnection peer,
  required ArcRtpTransceiver transceiver,
  String? trackId,
}) => RustLib.instance.api.crateApiSenderReplaceTrack(
  peer: peer,
  transceiver: transceiver,
  trackId: trackId,
);

/// Returns [`RtpParameters`] from the provided [`RtpTransceiver`]'s `sender`.
Future<RtcRtpSendParameters> senderGetParameters({
  required ArcRtpTransceiver transceiver,
}) =>
    RustLib.instance.api.crateApiSenderGetParameters(transceiver: transceiver);

/// Returns the capabilities of an [RTP] sender of the provided [`MediaType`].
///
/// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
Future<RtpCapabilities> getRtpSenderCapabilities({required MediaType kind}) =>
    RustLib.instance.api.crateApiGetRtpSenderCapabilities(kind: kind);

/// Returns the capabilities of an [RTP] receiver of the provided [`MediaType`].
///
/// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
Future<RtpCapabilities> getRtpReceiverCapabilities({required MediaType kind}) =>
    RustLib.instance.api.crateApiGetRtpReceiverCapabilities(kind: kind);

/// Sets [`RtpParameters`] into the provided [`RtpTransceiver`]'s `sender`.
Future<void> senderSetParameters({
  required ArcRtpTransceiver transceiver,
  required RtcRtpSendParameters params,
}) => RustLib.instance.api.crateApiSenderSetParameters(
  transceiver: transceiver,
  params: params,
);

/// Adds the new ICE `candidate` to the given [`PeerConnection`].
Future<void> addIceCandidate({
  required ArcPeerConnection peer,
  required String candidate,
  required String sdpMid,
  required int sdpMlineIndex,
}) => RustLib.instance.api.crateApiAddIceCandidate(
  peer: peer,
  candidate: candidate,
  sdpMid: sdpMid,
  sdpMlineIndex: sdpMlineIndex,
);

/// Tells the [`PeerConnection`] that ICE should be restarted.
Future<void> restartIce({required ArcPeerConnection peer}) =>
    RustLib.instance.api.crateApiRestartIce(peer: peer);

/// Closes the [`PeerConnection`].
Future<void> disposePeerConnection({required ArcPeerConnection peer}) =>
    RustLib.instance.api.crateApiDisposePeerConnection(peer: peer);

/// Creates a [MediaStream] with tracks according to provided
/// [`MediaStreamConstraints`].
///
/// [MediaStream]: https://w3.org/TR/mediacapture-streams#dom-mediastream
Future<GetMediaResult> getMedia({
  required MediaStreamConstraints constraints,
}) => RustLib.instance.api.crateApiGetMedia(constraints: constraints);

/// Sets the specified `audio playout` device.
Future<void> setAudioPlayoutDevice({required String deviceId}) =>
    RustLib.instance.api.crateApiSetAudioPlayoutDevice(deviceId: deviceId);

/// Indicates whether the microphone is available to set volume.
Future<bool> microphoneVolumeIsAvailable() =>
    RustLib.instance.api.crateApiMicrophoneVolumeIsAvailable();

/// Sets the microphone system volume according to the specified `level` in
/// percents.
///
/// Valid values range is `[0; 100]`.
Future<void> setMicrophoneVolume({required int level}) =>
    RustLib.instance.api.crateApiSetMicrophoneVolume(level: level);

/// Returns the current level of the microphone volume in `[0; 100]` range.
Future<int> microphoneVolume() =>
    RustLib.instance.api.crateApiMicrophoneVolume();

/// Disposes the specified [`MediaStreamTrack`].
Future<void> disposeTrack({
  required String trackId,
  int? peerId,
  required MediaType kind,
}) => RustLib.instance.api.crateApiDisposeTrack(
  trackId: trackId,
  peerId: peerId,
  kind: kind,
);

/// Returns the [readyState][0] property of the [`MediaStreamTrack`] by its ID
/// and [`MediaType`].
///
/// [0]: https://w3.org/TR/mediacapture-streams#dfn-readystate
Future<TrackState> trackState({
  required String trackId,
  int? peerId,
  required MediaType kind,
}) => RustLib.instance.api.crateApiTrackState(
  trackId: trackId,
  peerId: peerId,
  kind: kind,
);

/// Returns the [height] property of the media track by its ID and
/// [`MediaType`].
///
/// Blocks until the [height] is initialized.
///
/// [height]: https://w3.org/TR/mediacapture-streams#dfn-height
Future<int?> trackHeight({
  required String trackId,
  int? peerId,
  required MediaType kind,
}) => RustLib.instance.api.crateApiTrackHeight(
  trackId: trackId,
  peerId: peerId,
  kind: kind,
);

/// Returns the [width] property of the media track by its ID and [`MediaType`].
///
/// Blocks until the [width] is initialized.
///
/// [width]: https://w3.org/TR/mediacapture-streams#dfn-height
Future<int?> trackWidth({
  required String trackId,
  int? peerId,
  required MediaType kind,
}) => RustLib.instance.api.crateApiTrackWidth(
  trackId: trackId,
  peerId: peerId,
  kind: kind,
);

/// Changes the [enabled][1] property of the [`MediaStreamTrack`] by its ID and
/// [`MediaType`].
///
/// [1]: https://w3.org/TR/mediacapture-streams#track-enabled
Future<void> setTrackEnabled({
  required String trackId,
  int? peerId,
  required MediaType kind,
  required bool enabled,
}) => RustLib.instance.api.crateApiSetTrackEnabled(
  trackId: trackId,
  peerId: peerId,
  kind: kind,
  enabled: enabled,
);

/// Clones the specified [`MediaStreamTrack`].
Future<MediaStreamTrack?> cloneTrack({
  required String trackId,
  int? peerId,
  required MediaType kind,
}) => RustLib.instance.api.crateApiCloneTrack(
  trackId: trackId,
  peerId: peerId,
  kind: kind,
);

/// Registers an observer to the [`MediaStreamTrack`] events.
Stream<TrackEvent> registerTrackObserver({
  int? peerId,
  required String trackId,
  required MediaType kind,
}) => RustLib.instance.api.crateApiRegisterTrackObserver(
  peerId: peerId,
  trackId: trackId,
  kind: kind,
);

/// Enables or disables audio level observing of the audio [`MediaStreamTrack`]
/// with the provided `track_id`.
Future<void> setAudioLevelObserverEnabled({
  required String trackId,
  int? peerId,
  required bool enabled,
}) => RustLib.instance.api.crateApiSetAudioLevelObserverEnabled(
  trackId: trackId,
  peerId: peerId,
  enabled: enabled,
);

/// Applies the provided [`AudioProcessingConstraints`] to specified local audio
/// track.
Future<void> updateAudioProcessing({
  required String trackId,
  required AudioProcessingConstraints conf,
}) => RustLib.instance.api.crateApiUpdateAudioProcessing(
  trackId: trackId,
  conf: conf,
);

/// Returns the current [`AudioProcessingConfig`] for the specified local audio
/// track.
Future<AudioProcessingConfig> getAudioProcessingConfig({
  required String trackId,
}) => RustLib.instance.api.crateApiGetAudioProcessingConfig(trackId: trackId);

/// Sets the provided `OnDeviceChangeCallback` as the callback to be called
/// whenever a set of available media devices changes.
///
/// Only one callback can be set at a time, so the previous one will be dropped,
/// if any.
Stream<void> setOnDeviceChanged() =>
    RustLib.instance.api.crateApiSetOnDeviceChanged();

/// Creates a new [`VideoSink`] attached to the specified video track.
///
/// `callback_ptr` argument should be a pointer to an [`UniquePtr`] pointing to
/// an [`sys::OnFrameCallback`].
///
/// [`UniquePtr`]: cxx::UniquePtr
/// [`VideoSink`]: crate::VideoSink
Stream<TextureEvent> createVideoSink({
  required PlatformInt64 sinkId,
  int? peerId,
  required String trackId,
  required PlatformInt64 callbackPtr,
  required PlatformInt64 textureId,
}) => RustLib.instance.api.crateApiCreateVideoSink(
  sinkId: sinkId,
  peerId: peerId,
  trackId: trackId,
  callbackPtr: callbackPtr,
  textureId: textureId,
);

/// Destroys a [`VideoSink`] by the provided ID.
///
/// [`VideoSink`]: crate::VideoSink
Future<void> disposeVideoSink({required PlatformInt64 sinkId}) =>
    RustLib.instance.api.crateApiDisposeVideoSink(sinkId: sinkId);

/// Nature and settings of the audio [`MediaStreamTrack`] returned by
/// [`Webrtc::get_media()`].
class AudioConstraints {
  /// Identifier of the device generating the content of the
  /// [`MediaStreamTrack`].
  ///
  /// First device will be chosen if an empty [`String`] is provided.
  final String? deviceId;

  /// Audio processing configuration of the [`MediaStreamTrack`].
  final AudioProcessingConstraints processing;

  const AudioConstraints({this.deviceId, required this.processing});

  @override
  int get hashCode => deviceId.hashCode ^ processing.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is AudioConstraints &&
          runtimeType == other.runtimeType &&
          deviceId == other.deviceId &&
          processing == other.processing;
}

class AudioProcessingConfig {
  /// Indicator whether the audio volume level should be automatically tuned
  /// to maintain a steady overall volume level.
  final bool autoGainControl;

  /// Indicator whether a high-pass filter should be enabled to eliminate
  /// low-frequency noise.
  final bool highPassFilter;

  /// Indicator whether noise suppression should be enabled to reduce
  /// background sounds.
  final bool noiseSuppression;

  /// Level of aggressiveness for noise suppression.
  final NoiseSuppressionLevel noiseSuppressionLevel;

  /// Indicator whether echo cancellation should be enabled to prevent
  /// feedback.
  final bool echoCancellation;

  const AudioProcessingConfig({
    required this.autoGainControl,
    required this.highPassFilter,
    required this.noiseSuppression,
    required this.noiseSuppressionLevel,
    required this.echoCancellation,
  });

  @override
  int get hashCode =>
      autoGainControl.hashCode ^
      highPassFilter.hashCode ^
      noiseSuppression.hashCode ^
      noiseSuppressionLevel.hashCode ^
      echoCancellation.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is AudioProcessingConfig &&
          runtimeType == other.runtimeType &&
          autoGainControl == other.autoGainControl &&
          highPassFilter == other.highPassFilter &&
          noiseSuppression == other.noiseSuppression &&
          noiseSuppressionLevel == other.noiseSuppressionLevel &&
          echoCancellation == other.echoCancellation;
}

/// Audio processing configuration constraints.
class AudioProcessingConstraints {
  /// Indicator whether the audio volume level should be automatically tuned
  /// to maintain a steady overall volume level.
  final bool? autoGainControl;

  /// Indicator whether a high-pass filter should be enabled to eliminate
  /// low-frequency noise.
  final bool? highPassFilter;

  /// Indicator whether noise suppression should be enabled to reduce
  /// background sounds.
  final bool? noiseSuppression;

  /// Level of aggressiveness for noise suppression.
  final NoiseSuppressionLevel? noiseSuppressionLevel;

  /// Indicator whether echo cancellation should be enabled to prevent
  /// feedback.
  final bool? echoCancellation;

  const AudioProcessingConstraints({
    this.autoGainControl,
    this.highPassFilter,
    this.noiseSuppression,
    this.noiseSuppressionLevel,
    this.echoCancellation,
  });

  static Future<AudioProcessingConstraints> default_() =>
      RustLib.instance.api.crateApiAudioProcessingConstraintsDefault();

  @override
  int get hashCode =>
      autoGainControl.hashCode ^
      highPassFilter.hashCode ^
      noiseSuppression.hashCode ^
      noiseSuppressionLevel.hashCode ^
      echoCancellation.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is AudioProcessingConstraints &&
          runtimeType == other.runtimeType &&
          autoGainControl == other.autoGainControl &&
          highPassFilter == other.highPassFilter &&
          noiseSuppression == other.noiseSuppression &&
          noiseSuppressionLevel == other.noiseSuppressionLevel &&
          echoCancellation == other.echoCancellation;
}

/// [RTCBundlePolicy][1] representation.
///
/// Affects which media tracks are negotiated if the remote endpoint is not
/// bundle-aware, and what ICE candidates are gathered. If the remote endpoint
/// is bundle-aware, all media tracks and data channels are bundled onto the
/// same transport.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtcbundlepolicy
enum BundlePolicy {
  /// [RTCBundlePolicy.balanced][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcbundlepolicy-balanced
  balanced,

  /// [RTCBundlePolicy.max-bundle][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcbundlepolicy-max-bundle
  maxBundle,

  /// [RTCBundlePolicy.max-compat][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcbundlepolicy-max-compat
  maxCompat,
}

/// [RTCIceCandidateType] represents the type of the ICE candidate, as defined
/// in [Section 15.1 of RFC 5245][1].
///
/// [RTCIceCandidateType]: https://w3.org/TR/webrtc#rtcicecandidatetype-enum
/// [1]: https://tools.ietf.org/html/rfc5245#section-15.1
enum CandidateType {
  /// Host candidate, as defined in [Section 4.1.1.1 of RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-4.1.1.1
  host,

  /// Server reflexive candidate, as defined in
  /// [Section 4.1.1.2 of RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-4.1.1.2
  srflx,

  /// Peer reflexive candidate, as defined in
  /// [Section 4.1.1.2 of RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-4.1.1.2
  prflx,

  /// Relay candidate, as defined in [Section 7.1.3.2.1 of RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-7.1.3.2.1
  relay,
}

@freezed
sealed class GetMediaError with _$GetMediaError {
  const GetMediaError._();

  /// Could not acquire audio track.
  const factory GetMediaError.audio(String field0) = GetMediaError_Audio;

  /// Could not acquire video track.
  const factory GetMediaError.video(String field0) = GetMediaError_Video;
}

@freezed
sealed class GetMediaResult with _$GetMediaResult {
  const GetMediaResult._();

  /// Requested media tracks.
  const factory GetMediaResult.ok(List<MediaStreamTrack> field0) =
      GetMediaResult_Ok;

  /// Failed to get requested media.
  const factory GetMediaResult.err(GetMediaError field0) = GetMediaResult_Err;
}

/// Properties of a `candidate` in [Section 15.1 of RFC 5245][1].
/// It corresponds to an [RTCIceTransport] object.
///
/// [`RtcIceCandidateStats::Local`] or [`RtcIceCandidateStats::Remote`] variant.
///
/// [Full doc on W3C][2].
///
/// [RTCIceTransport]: https://w3.org/TR/webrtc#dom-rtcicetransport
/// [1]: https://tools.ietf.org/html/rfc5245#section-15.1
/// [2]: https://w3.org/TR/webrtc-stats#icecandidate-dict%2A
class IceCandidateStats {
  /// Unique ID that is associated to the object that was inspected to produce
  /// the [RTCTransportStats][1] associated with this candidate.
  ///
  /// [1]: https://w3.org/TR/webrtc-stats#transportstats-dict%2A
  final String? transportId;

  /// Address of the candidate, allowing for IPv4 addresses, IPv6 addresses,
  /// and fully qualified domain names (FQDNs).
  final String? address;

  /// Port number of the candidate.
  final int? port;

  /// Valid values for transport is one of `udp` and `tcp`.
  final Protocol protocol;

  /// Type of the ICE candidate.
  final CandidateType candidateType;

  /// Calculated as defined in [Section 15.1 of RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-15.1
  final int? priority;

  /// For local candidates this is the URL of the ICE server from which the
  /// candidate was obtained. It is the same as the [url][2] surfaced in the
  /// [RTCPeerConnectionIceEvent][1].
  ///
  /// [`None`] for remote candidates.
  ///
  /// [1]: https://w3.org/TR/webrtc#rtcpeerconnectioniceevent
  /// [2]: https://w3.org/TR/webrtc#dom-rtcpeerconnectioniceevent-url
  final String? url;

  /// Protocol used by the endpoint to communicate with the TURN server.
  ///
  /// Only present for local candidates.
  final Protocol? relayProtocol;

  const IceCandidateStats({
    this.transportId,
    this.address,
    this.port,
    required this.protocol,
    required this.candidateType,
    this.priority,
    this.url,
    this.relayProtocol,
  });

  @override
  int get hashCode =>
      transportId.hashCode ^
      address.hashCode ^
      port.hashCode ^
      protocol.hashCode ^
      candidateType.hashCode ^
      priority.hashCode ^
      url.hashCode ^
      relayProtocol.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is IceCandidateStats &&
          runtimeType == other.runtimeType &&
          transportId == other.transportId &&
          address == other.address &&
          port == other.port &&
          protocol == other.protocol &&
          candidateType == other.candidateType &&
          priority == other.priority &&
          url == other.url &&
          relayProtocol == other.relayProtocol;
}

/// [RTCIceConnectionState][1] representation.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate
enum IceConnectionState {
  /// [RTCIceConnectionState.new][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-new
  new_,

  /// [RTCIceConnectionState.checking][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-checking
  checking,

  /// [RTCIceConnectionState.connected][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-connected
  connected,

  /// [RTCIceConnectionState.completed][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-completed
  completed,

  /// [RTCIceConnectionState.failed][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-failed
  failed,

  /// [RTCIceConnectionState.disconnected][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-disconnected
  disconnected,

  /// [RTCIceConnectionState.closed][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceconnectionstate-closed
  closed,
}

/// [RTCIceGatheringState][1] representation.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtcicegatheringstate
enum IceGatheringState {
  /// [RTCIceGatheringState.new][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicegatheringstate-new
  new_,

  /// [RTCIceGatheringState.gathering][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicegatheringstate-gathering
  gathering,

  /// [RTCIceGatheringState.complete][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicegatheringstate-complete
  complete,
}

/// Variants of [ICE roles][1].
///
/// More info in the [RFC 5245].
///
/// [RFC 5245]: https://tools.ietf.org/html/rfc5245
/// [1]: https://w3.org/TR/webrtc#dom-icetransport-role
enum IceRole {
  /// Agent whose role as defined by [Section 3 in RFC 5245][1], has not yet
  /// been determined.
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-3
  unknown,

  /// Controlling agent as defined by [Section 3 in RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-3
  controlling,

  /// Controlled agent as defined by [Section 3 in RFC 5245][1].
  ///
  /// [1]: https://tools.ietf.org/html/rfc5245#section-3
  controlled,
}

/// [RTCIceTransportPolicy][1] representation.
///
/// It defines an ICE candidate policy the [ICE Agent][2] uses to surface
/// the permitted candidates to the application. Only these candidates will
/// be used for connectivity checks.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtcicetransportpolicy
/// [2]: https://w3.org/TR/webrtc#dfn-ice-agent
enum IceTransportsType {
  /// [RTCIceTransportPolicy.all][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicetransportpolicy-all
  all,

  /// [RTCIceTransportPolicy.relay][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicetransportpolicy-relay
  relay,

  /// ICE Agent can't use `typ host` candidates when this value is specified.
  ///
  /// Non-spec-compliant variant.
  noHost,

  /// No ICE candidate offered.
  none,
}

/// Information describing a single media input or output device.
class MediaDeviceInfo {
  /// Unique identifier for the represented device.
  final String deviceId;

  /// Kind of the represented device.
  final MediaDeviceKind kind;

  /// Label describing the represented device.
  final String label;

  const MediaDeviceInfo({
    required this.deviceId,
    required this.kind,
    required this.label,
  });

  @override
  int get hashCode => deviceId.hashCode ^ kind.hashCode ^ label.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is MediaDeviceInfo &&
          runtimeType == other.runtimeType &&
          deviceId == other.deviceId &&
          kind == other.kind &&
          label == other.label;
}

/// Possible kinds of media devices.
enum MediaDeviceKind {
  /// Audio input device (for example, a microphone).
  audioInput,

  /// Audio output device (for example, a pair of headphones).
  audioOutput,

  /// Video input device (for example, a webcam).
  videoInput,
}

/// Information describing a display.
class MediaDisplayInfo {
  /// Unique identifier of the device representing the display.
  final String deviceId;

  /// Title describing the represented display.
  final String? title;

  const MediaDisplayInfo({required this.deviceId, this.title});

  @override
  int get hashCode => deviceId.hashCode ^ title.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is MediaDisplayInfo &&
          runtimeType == other.runtimeType &&
          deviceId == other.deviceId &&
          title == other.title;
}

/// [MediaStreamConstraints], used to instruct what sort of
/// [`MediaStreamTrack`]s to return by the [`Webrtc::get_media()`].
///
/// [1]: https://w3.org/TR/mediacapture-streams#dom-mediastreamconstraints
class MediaStreamConstraints {
  /// Specifies the nature and settings of the audio [`MediaStreamTrack`].
  final AudioConstraints? audio;

  /// Specifies the nature and settings of the video [`MediaStreamTrack`].
  final VideoConstraints? video;

  const MediaStreamConstraints({this.audio, this.video});

  @override
  int get hashCode => audio.hashCode ^ video.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is MediaStreamConstraints &&
          runtimeType == other.runtimeType &&
          audio == other.audio &&
          video == other.video;
}

/// Representation of a single media track within a [MediaStream].
///
/// Typically, these are audio or video tracks, but other track types may exist
/// as well.
///
/// [MediaStream]: https://w3.org/TR/mediacapture-streams#dom-mediastream
class MediaStreamTrack {
  /// Unique identifier (GUID) of this [`MediaStreamTrack`].
  final String id;

  /// Unique identifier of the [`PeerConnection`] from which this
  /// [`MediaStreamTrack`] was received.
  ///
  /// Always [`None`] for local [`MediaStreamTrack`]s.
  final int? peerId;

  /// Label identifying the track source, as in "internal microphone".
  final String deviceId;

  /// [`MediaType`] of this [`MediaStreamTrack`].
  final MediaType kind;

  /// Indicator whether this [`MediaStreamTrack`] is allowed to render the
  /// source stream.
  ///
  /// This can be used to intentionally mute a track.
  final bool enabled;

  const MediaStreamTrack({
    required this.id,
    this.peerId,
    required this.deviceId,
    required this.kind,
    required this.enabled,
  });

  @override
  int get hashCode =>
      id.hashCode ^
      peerId.hashCode ^
      deviceId.hashCode ^
      kind.hashCode ^
      enabled.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is MediaStreamTrack &&
          runtimeType == other.runtimeType &&
          id == other.id &&
          peerId == other.peerId &&
          deviceId == other.deviceId &&
          kind == other.kind &&
          enabled == other.enabled;
}

/// Possible media types of a [`MediaStreamTrack`].
enum MediaType {
  /// Audio [`MediaStreamTrack`].
  audio,

  /// Video [`MediaStreamTrack`].
  video,
}

/// [`AudioProcessingConfig`] noise suppression aggressiveness.
enum NoiseSuppressionLevel {
  /// Minimal noise suppression.
  low,

  /// Moderate level of suppression.
  moderate,

  /// Aggressive noise suppression.
  high,

  /// Maximum suppression.
  veryHigh,
}

@freezed
sealed class PeerConnectionEvent with _$PeerConnectionEvent {
  const PeerConnectionEvent._();

  /// [`PeerConnection`] has been created.
  const factory PeerConnectionEvent.peerCreated({
    /// Rust side [`PeerConnection`].
    required ArcPeerConnection peer,
  }) = PeerConnectionEvent_PeerCreated;

  /// [RTCIceCandidate][1] has been discovered.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
  const factory PeerConnectionEvent.iceCandidate({
    /// Media stream "identification-tag" defined in [RFC 5888] for the
    /// media component the discovered [RTCIceCandidate][1] is associated
    /// with.
    ///
    /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
    /// [RFC 5888]: https://tools.ietf.org/html/rfc5888
    required String sdpMid,

    /// Index (starting at zero) of the media description in the SDP this
    /// [RTCIceCandidate][1] is associated with.
    ///
    /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
    required int sdpMlineIndex,

    /// Candidate-attribute as defined in Section 15.1 of [RFC 5245].
    ///
    /// If this [RTCIceCandidate][1] represents an end-of-candidates
    /// indication or a peer reflexive remote candidate, candidate is an
    /// empty string.
    ///
    /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
    /// [RFC 5245]: https://tools.ietf.org/html/rfc5245
    required String candidate,
  }) = PeerConnectionEvent_IceCandidate;

  /// [`PeerConnection`]'s ICE gathering state has changed.
  const factory PeerConnectionEvent.iceGatheringStateChange(
    IceGatheringState field0,
  ) = PeerConnectionEvent_IceGatheringStateChange;

  /// Failure occurred when gathering [RTCIceCandidate][1].
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcicecandidate
  const factory PeerConnectionEvent.iceCandidateError({
    /// Local IP address used to communicate with the STUN or TURN server.
    required String address,

    /// Port used to communicate with the STUN or TURN server.
    required int port,

    /// STUN or TURN URL identifying the STUN or TURN server for which the
    /// failure occurred.
    required String url,

    /// Numeric STUN error code returned by the STUN or TURN server
    /// [`STUN-PARAMETERS`][1].
    ///
    /// If no host candidate can reach the server, it will be set to the
    /// value `701` which is outside the STUN error code range.
    ///
    /// [1]: https://tinyurl.com/stun-parameters-6
    required int errorCode,

    /// STUN reason text returned by the STUN or TURN server
    /// [`STUN-PARAMETERS`][1].
    ///
    /// If the server could not be reached, it will be set to an
    /// implementation-specific value providing details about the error.
    ///
    /// [1]: https://tinyurl.com/stun-parameters-6
    required String errorText,
  }) = PeerConnectionEvent_IceCandidateError;

  /// Negotiation or renegotiation of the [`PeerConnection`] needs to be
  /// performed.
  const factory PeerConnectionEvent.negotiationNeeded() =
      PeerConnectionEvent_NegotiationNeeded;

  /// [`PeerConnection`]'s [`SignalingState`] has been changed.
  const factory PeerConnectionEvent.signallingChange(SignalingState field0) =
      PeerConnectionEvent_SignallingChange;

  /// [`PeerConnection`]'s [`IceConnectionState`] has been changed.
  const factory PeerConnectionEvent.iceConnectionStateChange(
    IceConnectionState field0,
  ) = PeerConnectionEvent_IceConnectionStateChange;

  /// [`PeerConnection`]'s [`PeerConnectionState`] has been changed.
  const factory PeerConnectionEvent.connectionStateChange(
    PeerConnectionState field0,
  ) = PeerConnectionEvent_ConnectionStateChange;

  /// New incoming media has been negotiated.
  const factory PeerConnectionEvent.track(RtcTrackEvent field0) =
      PeerConnectionEvent_Track;
}

/// Indicator of the current state of a [`PeerConnection`].
enum PeerConnectionState {
  /// At least one of the connection's ICE transports is in the new state,
  /// and none of them are in one of the following states: `connecting`,
  /// `checking`, `failed`, `disconnected`, or all of the connection's
  /// transports are in the `closed` state.
  new_,

  /// One or more of the ICE transports are currently in the process of
  /// establishing a connection. That is, their [`IceConnectionState`] is
  /// either [`IceConnectionState::Checking`] or
  /// [`IceConnectionState::Connected`], and no transports are in the
  /// `failed` state.
  connecting,

  /// Every ICE transport used by the connection is either in use (state
  /// `connected` or `completed`) or is closed (state `closed`). In addition,
  /// at least one transport is either `connected` or `completed`.
  connected,

  /// At least one of the ICE transports for the connection is in the
  /// `disconnected` state and none of the other transports are in the state
  /// `failed`, `connecting` or `checking`.
  disconnected,

  /// One or more of the ICE transports on the connection is in the `failed`
  /// state.
  failed,

  /// Peer connection is closed.
  closed,
}

/// Transport protocols used in [WebRTC].
///
/// [WebRTC]: https://w3.org/TR/webrtc
enum Protocol {
  /// [Transmission Control Protocol][1].
  ///
  /// [1]: https://en.wikipedia.org/wiki/Transmission_Control_Protocol
  tcp,

  /// [User Datagram Protocol][1].
  ///
  /// [1]: https://en.wikipedia.org/wiki/User_Datagram_Protocol
  udp,
}

/// [`PeerConnection`]'s configuration.
class RtcConfiguration {
  /// [iceTransportPolicy][1] configuration.
  ///
  /// Indicates which candidates the [ICE Agent][2] is allowed to use.
  ///
  /// [1]: https://tinyurl.com/icetransportpolicy
  /// [2]: https://w3.org/TR/webrtc#dfn-ice-agent
  final IceTransportsType iceTransportPolicy;

  /// [bundlePolicy][1] configuration.
  ///
  /// Indicates which media-bundling policy to use when gathering ICE
  /// candidates.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcconfiguration-bundlepolicy
  final BundlePolicy bundlePolicy;

  /// [iceServers][1] configuration.
  ///
  /// An array of objects describing servers available to be used by ICE,
  /// such as STUN and TURN servers.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcconfiguration-iceservers
  final List<RtcIceServer> iceServers;

  const RtcConfiguration({
    required this.iceTransportPolicy,
    required this.bundlePolicy,
    required this.iceServers,
  });

  @override
  int get hashCode =>
      iceTransportPolicy.hashCode ^ bundlePolicy.hashCode ^ iceServers.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcConfiguration &&
          runtimeType == other.runtimeType &&
          iceTransportPolicy == other.iceTransportPolicy &&
          bundlePolicy == other.bundlePolicy &&
          iceServers == other.iceServers;
}

@freezed
sealed class RtcIceCandidateStats with _$RtcIceCandidateStats {
  const RtcIceCandidateStats._();

  /// [`IceCandidateStats`] of local candidate.
  const factory RtcIceCandidateStats.local(IceCandidateStats field0) =
      RtcIceCandidateStats_Local;

  /// [`IceCandidateStats`] of remote candidate.
  const factory RtcIceCandidateStats.remote(IceCandidateStats field0) =
      RtcIceCandidateStats_Remote;
}

/// Description of STUN and TURN servers that can be used by an [ICE Agent][1]
/// to establish a connection with a peer.
///
/// [1]: https://w3.org/TR/webrtc#dfn-ice-agent
class RtcIceServer {
  /// STUN or TURN URI(s).
  final List<String> urls;

  /// If this [`RtcIceServer`] object represents a TURN server, then this
  /// attribute specifies the [username][1] to use with that TURN server.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceserver-username
  final String username;

  /// If this [`RtcIceServer`] object represents a TURN server, then this
  /// attribute specifies the [credential][1] to use with that TURN
  /// server.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtciceserver-credential
  final String credential;

  const RtcIceServer({
    required this.urls,
    required this.username,
    required this.credential,
  });

  @override
  int get hashCode => urls.hashCode ^ username.hashCode ^ credential.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcIceServer &&
          runtimeType == other.runtimeType &&
          urls == other.urls &&
          username == other.username &&
          credential == other.credential;
}

@freezed
sealed class RtcInboundRtpStreamMediaType with _$RtcInboundRtpStreamMediaType {
  const RtcInboundRtpStreamMediaType._();

  /// `audio` media type fields.
  const factory RtcInboundRtpStreamMediaType.audio({
    /// Indicator whether the last RTP packet whose frame was delivered to
    /// the [RTCRtpReceiver]'s [MediaStreamTrack][1] for playout contained
    /// voice activity or not based on the presence of the V bit in the
    /// extension header, as defined in [RFC 6464].
    ///
    /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#rtcrtpreceiver-interface
    /// [RFC 6464]: https://tools.ietf.org/html/rfc6464#page-3
    /// [1]: https://w3.org/TR/mediacapture-streams#mediastreamtrack
    bool? voiceActivityFlag,

    /// Total number of samples that have been received on this RTP stream.
    /// This includes [concealedSamples].
    ///
    /// [concealedSamples]: https://tinyurl.com/s6c4qe4
    BigInt? totalSamplesReceived,

    /// Total number of samples that are concealed samples.
    ///
    /// A concealed sample is a sample that was replaced with synthesized
    /// samples generated locally before being played out.
    /// Examples of samples that have to be concealed are samples from lost
    /// packets (reported in [packetsLost]) or samples from packets that
    /// arrive too late to be played out (reported in [packetsDiscarded]).
    ///
    /// [packetsLost]: https://tinyurl.com/u2gq965
    /// [packetsDiscarded]: https://tinyurl.com/yx7qyox3
    BigInt? concealedSamples,

    /// Total number of concealed samples inserted that are "silent".
    ///
    /// Playing out silent samples results in silence or comfort noise.
    /// This is a subset of [concealedSamples].
    ///
    /// [concealedSamples]: https://tinyurl.com/s6c4qe4
    BigInt? silentConcealedSamples,

    /// Audio level of the receiving track.
    double? audioLevel,

    /// Audio energy of the receiving track.
    double? totalAudioEnergy,

    /// Audio duration of the receiving track.
    ///
    /// For audio durations of tracks attached locally, see
    /// [RTCAudioSourceStats][1] instead.
    ///
    /// [1]: https://w3.org/TR/webrtc-stats#dom-rtcaudiosourcestats
    double? totalSamplesDuration,
  }) = RtcInboundRtpStreamMediaType_Audio;

  /// `video` media type fields.
  const factory RtcInboundRtpStreamMediaType.video({
    /// Total number of frames correctly decoded for this RTP stream, i.e.
    /// frames that would be displayed if no frames are dropped.
    int? framesDecoded,

    /// Total number of key frames, such as key frames in VP8 [RFC 6386] or
    /// IDR-frames in H.264 [RFC 6184], successfully decoded for this RTP
    /// media stream.
    ///
    /// This is a subset of [framesDecoded].
    /// [framesDecoded] - [keyFramesDecoded] gives you the number of delta
    /// frames decoded.
    ///
    /// [RFC 6386]: https://w3.org/TR/webrtc-stats#bib-rfc6386
    /// [RFC 6184]: https://w3.org/TR/webrtc-stats#bib-rfc6184
    /// [framesDecoded]: https://tinyurl.com/srfwrwt
    /// [keyFramesDecoded]: https://tinyurl.com/qtdmhtm
    int? keyFramesDecoded,

    /// Width of the last decoded frame.
    ///
    /// Before the first frame is decoded this attribute is missing.
    int? frameWidth,

    /// Height of the last decoded frame.
    ///
    /// Before the first frame is decoded this attribute is missing.
    int? frameHeight,

    /// Sum of the interframe delays in seconds between consecutively
    /// decoded frames, recorded just after a frame has been decoded.
    double? totalInterFrameDelay,

    /// Number of decoded frames in the last second.
    double? framesPerSecond,

    /// Total number of Full Intra Request (FIR) packets sent by this
    /// receiver.
    int? firCount,

    /// Total number of Picture Loss Indication (PLI) packets sent by this
    /// receiver.
    int? pliCount,

    /// Total number of Slice Loss Indication (SLI) packets sent by this
    /// receiver.
    int? sliCount,

    /// Number of concealment events.
    ///
    /// This counter increases every time a concealed sample is synthesized
    /// after a non-concealed sample. That is, multiple consecutive
    /// concealed samples will increase the [concealedSamples] count
    /// multiple times but is a single concealment event.
    ///
    /// [concealedSamples]: https://tinyurl.com/s6c4qe4
    BigInt? concealmentEvents,

    /// Total number of complete frames received on this RTP stream.
    ///
    /// This metric is incremented when the complete frame is received.
    int? framesReceived,
  }) = RtcInboundRtpStreamMediaType_Video;
}

@freezed
sealed class RtcMediaSourceStatsMediaType with _$RtcMediaSourceStatsMediaType {
  const RtcMediaSourceStatsMediaType._();

  /// Video source fields.
  const factory RtcMediaSourceStatsMediaType.rtcVideoSourceStats({
    /// Width (in pixels) of the last frame originating from the source.
    /// Before a frame has been produced this attribute is missing.
    int? width,

    /// Height (in pixels) of the last frame originating from the source.
    /// Before a frame has been produced this attribute is missing.
    int? height,

    /// Total number of frames originating from this source.
    int? frames,

    /// Number of frames originating from the source, measured during the
    /// last second. For the first second of this object's lifetime this
    /// attribute is missing.
    double? framesPerSecond,
  }) = RtcMediaSourceStatsMediaType_RtcVideoSourceStats;

  /// Audio source fields.
  const factory RtcMediaSourceStatsMediaType.rtcAudioSourceStats({
    /// Audio level of the media source.
    double? audioLevel,

    /// Audio energy of the media source.
    double? totalAudioEnergy,

    /// Audio duration of the media source.
    double? totalSamplesDuration,

    /// Only exists when the [MediaStreamTrack][1] is sourced from a
    /// microphone where echo cancellation is applied.
    ///
    /// [1]: https://w3.org/TR/mediacapture-streams#mediastreamtrack
    double? echoReturnLoss,

    /// Only exists when the [MediaStreamTrack][1] is sourced from a
    /// microphone where echo cancellation is applied.
    ///
    /// [1]: https://w3.org/TR/mediacapture-streams#mediastreamtrack
    double? echoReturnLossEnhancement,
  }) = RtcMediaSourceStatsMediaType_RtcAudioSourceStats;
}

@freezed
sealed class RtcOutboundRtpStreamStatsMediaType
    with _$RtcOutboundRtpStreamStatsMediaType {
  const RtcOutboundRtpStreamStatsMediaType._();

  /// `audio` media type fields.
  const factory RtcOutboundRtpStreamStatsMediaType.audio({
    /// Total number of samples that have been sent over the RTP stream.
    BigInt? totalSamplesSent,

    /// Whether the last RTP packet sent contained voice activity or not
    /// based on the presence of the V bit in the extension header.
    bool? voiceActivityFlag,
  }) = RtcOutboundRtpStreamStatsMediaType_Audio;

  /// `video` media type fields.
  const factory RtcOutboundRtpStreamStatsMediaType.video({
    /// Width of the last encoded frame.
    ///
    /// The resolution of the encoded frame may be lower than the media
    /// source (see [RTCVideoSourceStats.width][1]).
    ///
    /// Before the first frame is encoded this attribute is missing.
    ///
    /// [1]: https://w3.org/TR/webrtc-stats#dom-rtcvideosourcestats-width
    int? frameWidth,

    /// Height of the last encoded frame.
    ///
    /// The resolution of the encoded frame may be lower than the media
    /// source (see [RTCVideoSourceStats.height][1]).
    ///
    /// Before the first frame is encoded this attribute is missing.
    ///
    /// [1]: https://w3.org/TR/webrtc-stats#dom-rtcvideosourcestats-height
    int? frameHeight,

    /// Number of encoded frames during the last second.
    ///
    /// This may be lower than the media source frame rate (see
    /// [RTCVideoSourceStats.framesPerSecond][1]).
    ///
    /// [1]: https://tinyurl.com/rrmkrfk
    double? framesPerSecond,
  }) = RtcOutboundRtpStreamStatsMediaType_Video;
}

/// Representation of [RTCRtpEncodingParameters][0].
///
/// [0]: https://w3.org/TR/webrtc#rtcrtpencodingparameters
class RtcRtpEncodingParameters {
  /// [RTP stream ID (RID)][0] to be sent using the RID header extension.
  ///
  /// [0]: https://w3.org/TR/webrtc#dom-rtcrtpcodingparameters-rid
  final String rid;

  /// Indicator whether the described [`RtcRtpEncodingParameters`] are
  /// currently actively being used.
  final bool active;

  /// Maximum number of bits per second to allow for these
  /// [`RtcRtpEncodingParameters`].
  final int? maxBitrate;

  /// Maximum number of frames per second to allow for these
  /// [`RtcRtpEncodingParameters`].
  final double? maxFramerate;

  /// Factor for scaling down the video with these
  /// [`RtcRtpEncodingParameters`].
  final double? scaleResolutionDownBy;

  /// Scalability mode describing layers within the media stream.
  final String? scalabilityMode;

  const RtcRtpEncodingParameters({
    required this.rid,
    required this.active,
    this.maxBitrate,
    this.maxFramerate,
    this.scaleResolutionDownBy,
    this.scalabilityMode,
  });

  @override
  int get hashCode =>
      rid.hashCode ^
      active.hashCode ^
      maxBitrate.hashCode ^
      maxFramerate.hashCode ^
      scaleResolutionDownBy.hashCode ^
      scalabilityMode.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcRtpEncodingParameters &&
          runtimeType == other.runtimeType &&
          rid == other.rid &&
          active == other.active &&
          maxBitrate == other.maxBitrate &&
          maxFramerate == other.maxFramerate &&
          scaleResolutionDownBy == other.scaleResolutionDownBy &&
          scalabilityMode == other.scalabilityMode;
}

/// Representation of [RTCRtpSendParameters][0].
///
/// [0]: https://w3.org/TR/webrtc#dom-rtcrtpsendparameters
class RtcRtpSendParameters {
  /// Sequence containing parameters for sending [RTP] encodings of media.
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  final List<(RtcRtpEncodingParameters, ArcRtpEncodingParameters)> encodings;

  /// Reference to the Rust side [`RtpParameters`].
  final ArcRtpParameters inner;

  const RtcRtpSendParameters({required this.encodings, required this.inner});

  @override
  int get hashCode => encodings.hashCode ^ inner.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcRtpSendParameters &&
          runtimeType == other.runtimeType &&
          encodings == other.encodings &&
          inner == other.inner;
}

/// Representation of a permanent pair of an [RTCRtpSender] and an
/// [RTCRtpReceiver], along with some shared state.
///
/// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
/// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
class RtcRtpTransceiver {
  /// [`PeerConnection`] that this [`RtcRtpTransceiver`] belongs to.
  final ArcPeerConnection peer;

  /// Rust side [`RtpTransceiver`].
  final ArcRtpTransceiver transceiver;

  /// [Negotiated media ID (mid)][1] which the local and remote peers have
  /// agreed upon to uniquely identify the [MediaStream]'s pairing of sender
  /// and receiver.
  ///
  /// [MediaStream]: https://w3.org/TR/mediacapture-streams#dom-mediastream
  /// [1]: https://w3.org/TR/webrtc#dfn-media-stream-identification-tag
  final String? mid;

  /// Preferred [`direction`][1] of this [`RtcRtpTransceiver`].
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver-direction
  final RtpTransceiverDirection direction;

  const RtcRtpTransceiver({
    required this.peer,
    required this.transceiver,
    this.mid,
    required this.direction,
  });

  @override
  int get hashCode =>
      peer.hashCode ^ transceiver.hashCode ^ mid.hashCode ^ direction.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcRtpTransceiver &&
          runtimeType == other.runtimeType &&
          peer == other.peer &&
          transceiver == other.transceiver &&
          mid == other.mid &&
          direction == other.direction;
}

/// [RTCSessionDescription] representation.
///
/// [RTCSessionDescription]: https://w3.org/TR/webrtc#dom-rtcsessiondescription
class RtcSessionDescription {
  /// String representation of the SDP.
  final String sdp;

  /// Type of this [`RtcSessionDescription`].
  final SdpType kind;

  const RtcSessionDescription({required this.sdp, required this.kind});

  @override
  int get hashCode => sdp.hashCode ^ kind.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcSessionDescription &&
          runtimeType == other.runtimeType &&
          sdp == other.sdp &&
          kind == other.kind;
}

/// Represents the [stats object] constructed by inspecting a specific
/// [monitored object].
///
/// [Full doc on W3C][1].
///
/// [stats object]: https://w3.org/TR/webrtc-stats#dfn-stats-object
/// [monitored object]: https://w3.org/TR/webrtc-stats#dfn-monitored-object
/// [1]: https://w3.org/TR/webrtc#rtcstats-dictionary
class RtcStats {
  /// Unique ID that is associated with the object that was inspected to
  /// produce this [RTCStats] object.
  ///
  /// [RTCStats]: https://w3.org/TR/webrtc#dom-rtcstats
  final String id;

  /// Timestamp associated with this object.
  ///
  /// The time is relative to the UNIX epoch (Jan 1, 1970, UTC).
  ///
  /// For statistics that came from a remote source (e.g., from received RTCP
  /// packets), timestamp represents the time at which the information
  /// arrived at the local endpoint. The remote timestamp can be found in an
  /// additional field in an [`RtcStats`]-derived dictionary, if applicable.
  final PlatformInt64 timestampUs;

  /// Actual stats of these [`RtcStats`].
  ///
  /// All possible stats are described in the [`RtcStatsType`] enum.
  final RtcStatsType kind;

  const RtcStats({
    required this.id,
    required this.timestampUs,
    required this.kind,
  });

  @override
  int get hashCode => id.hashCode ^ timestampUs.hashCode ^ kind.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcStats &&
          runtimeType == other.runtimeType &&
          id == other.id &&
          timestampUs == other.timestampUs &&
          kind == other.kind;
}

/// Each candidate pair in the check list has a foundation and a state.
///
/// The foundation is the combination of the foundations of the local and remote
/// candidates in the pair. The state is assigned once the check list for each
/// media stream has been computed. There are five potential values that the
/// state can have.
enum RtcStatsIceCandidatePairState {
  /// Check for this pair hasn't been performed, and it can't yet be performed
  /// until some other check succeeds, allowing this pair to unfreeze and move
  /// into the [`RtcStatsIceCandidatePairState::Waiting`] state.
  frozen,

  /// Check has not been performed for this pair, and can be performed as soon
  /// as it is the highest-priority Waiting pair on the check list.
  waiting,

  /// Check has been sent for this pair, but the transaction is in progress.
  inProgress,

  /// Check for this pair was already done and failed, either never producing
  /// any response or producing an unrecoverable failure response.
  failed,

  /// Check for this pair was already done and produced a successful result.
  succeeded,
}

@freezed
sealed class RtcStatsType with _$RtcStatsType {
  const RtcStatsType._();

  /// Statistics for the media produced by a [MediaStreamTrack][1] that is
  /// currently attached to an [RTCRtpSender]. This reflects the media that is
  /// fed to the encoder after [getUserMedia()] constraints have been applied
  /// (i.e. not the raw media produced by the camera).
  ///
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#rtcrtpsender-interface
  /// [getUserMedia()]: https://tinyurl.com/sngpyr6
  /// [1]: https://w3.org/TR/mediacapture-streams#mediastreamtrack
  const factory RtcStatsType.rtcMediaSourceStats({
    /// Value of the [MediaStreamTrack][1]'s ID attribute.
    ///
    /// [1]: https://w3.org/TR/mediacapture-streams#mediastreamtrack
    String? trackIdentifier,

    /// Fields which should be in these [`RtcStats`] based on their `kind`.
    required RtcMediaSourceStatsMediaType kind,
  }) = RtcStatsType_RtcMediaSourceStats;

  /// ICE remote candidate statistics related to the [RTCIceTransport]
  /// objects.
  ///
  /// A remote candidate is [deleted][1] when the [RTCIceTransport] does an
  /// ICE restart, and the candidate is no longer a member of any non-deleted
  /// candidate pair.
  ///
  /// [RTCIceTransport]: https://w3.org/TR/webrtc#dom-rtcicetransport
  /// [1]: https://w3.org/TR/webrtc-stats#dfn-deleted
  const factory RtcStatsType.rtcIceCandidateStats(RtcIceCandidateStats field0) =
      RtcStatsType_RtcIceCandidateStats;

  /// Statistics for an outbound [RTP] stream that is currently sent with
  /// [RTCPeerConnection] object.
  ///
  /// When there are multiple [RTP] streams connected to the same sender, such
  /// as when using simulcast or RTX, there will be one
  /// [RTCOutboundRtpStreamStats][5] per RTP stream, with distinct values of
  /// the [SSRC] attribute, and all these senders will have a reference to the
  /// same "sender" object (of type [RTCAudioSenderStats][1] or
  /// [RTCVideoSenderStats][2]) and "track" object (of type
  /// [RTCSenderAudioTrackAttachmentStats][3] or
  /// [RTCSenderVideoTrackAttachmentStats][4]).
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
  /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
  /// [1]: https://w3.org/TR/webrtc-stats#dom-rtcaudiosenderstats
  /// [2]: https://w3.org/TR/webrtc-stats#dom-rtcvideosenderstats
  /// [3]: https://tinyurl.com/sefa5z4
  /// [4]: https://tinyurl.com/rkuvpl4
  /// [5]: https://w3.org/TR/webrtc-stats#dom-rtcoutboundrtpstreamstats
  const factory RtcStatsType.rtcOutboundRtpStreamStats({
    /// ID of the stats object representing the current track attachment to
    /// the sender of the stream.
    String? trackId,

    /// Fields which should be in these [`RtcStats`] based on their
    /// `media_type`.
    required RtcOutboundRtpStreamStatsMediaType mediaType,

    /// Total number of bytes sent for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    BigInt? bytesSent,

    /// Total number of RTP packets sent for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    int? packetsSent,

    /// ID of the stats object representing the track currently attached to
    /// the sender of the stream.
    String? mediaSourceId,
  }) = RtcStatsType_RtcOutboundRtpStreamStats;

  /// Statistics for an inbound [RTP] stream that is currently received with
  /// [RTCPeerConnection] object.
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
  const factory RtcStatsType.rtcInboundRtpStreamStats({
    /// ID of the stats object representing the receiving track.
    String? remoteId,

    /// Total number of bytes received for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    BigInt? bytesReceived,

    /// Total number of RTP data packets received for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    int? packetsReceived,

    /// Total number of RTP data packets for this [SSRC] that have been lost
    /// since the beginning of reception.
    ///
    /// This number is defined to be the number of packets expected less the
    /// number of packets actually received, where the number of packets
    /// received includes any which are late or duplicates. Thus, packets
    /// that arrive late are not counted as lost, and the loss
    /// **may be negative** if there are duplicates.
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    BigInt? packetsLost,

    /// Packet jitter measured in seconds for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    double? jitter,

    /// Total number of seconds that have been spent decoding the
    /// [framesDecoded] frames of the stream.
    ///
    /// The average decode time can be calculated by dividing this value
    /// with [framesDecoded]. The time it takes to decode one frame is the
    /// time passed between feeding the decoder a frame and the decoder
    /// returning decoded data for that frame.
    ///
    /// [framesDecoded]: https://tinyurl.com/srfwrwt
    double? totalDecodeTime,

    /// Total number of audio samples or video frames that have come out of
    /// the jitter buffer (increasing [jitterBufferDelay]).
    ///
    /// [jitterBufferDelay]: https://tinyurl.com/qvoojt5
    BigInt? jitterBufferEmittedCount,

    /// Fields which should be in these [`RtcStats`] based on their
    /// `media_type`.
    RtcInboundRtpStreamMediaType? mediaType,
  }) = RtcStatsType_RtcInboundRtpStreamStats;

  /// ICE candidate pair statistics related to the [RTCIceTransport] objects.
  ///
  /// A candidate pair that is not the current pair for a transport is
  /// [deleted] when the [RTCIceTransport] does an ICE restart, at the time
  /// the state changes to [new].
  ///
  /// The candidate pair that is the current pair for a transport is [deleted]
  /// after an ICE restart when the [RTCIceTransport] switches to using a
  /// candidate pair generated from the new candidates; this time doesn't
  /// correspond to any other externally observable event.
  ///
  /// [deleted]: https://w3.org/TR/webrtc-stats#dfn-deleted
  /// [new]: https://w3.org/TR/webrtc#dom-rtcicetransportstate-new
  /// [RTCIceTransport]: https://w3.org/TR/webrtc#dom-rtcicetransport
  const factory RtcStatsType.rtcIceCandidatePairStats({
    /// State of the checklist for the local and remote candidates in a
    /// pair.
    required RtcStatsIceCandidatePairState state,

    /// Related to updating the nominated flag described in
    /// [Section 7.1.3.2.4 of RFC 5245][1].
    ///
    /// [1]: https://tools.ietf.org/html/rfc5245#section-7.1.3.2.4
    bool? nominated,

    /// Total number of payload bytes sent on this candidate pair, i.e. not
    /// including headers or padding.
    BigInt? bytesSent,

    /// Total number of payload bytes received on this candidate pair, i.e.
    /// not including headers or padding.
    BigInt? bytesReceived,

    /// Sum of all round trip time measurements in seconds since the
    /// beginning of the session, based on STUN connectivity check
    /// [STUN-PATH-CHAR] responses ([responsesReceived][2]), including those
    /// that reply to requests that are sent in order to verify consent
    /// [RFC 7675].
    ///
    /// The average round trip time can be computed from
    /// [totalRoundTripTime][1] by dividing it by [responsesReceived][2].
    ///
    /// [STUN-PATH-CHAR]: https://w3.org/TR/webrtc-stats#bib-stun-path-char
    /// [RFC 7675]: https://tools.ietf.org/html/rfc7675
    /// [1]: https://tinyurl.com/tgr543a
    /// [2]: https://tinyurl.com/r3zo2um
    double? totalRoundTripTime,

    /// Latest round trip time measured in seconds, computed from both STUN
    /// connectivity checks [STUN-PATH-CHAR], including those that are sent
    /// for consent verification [RFC 7675].
    ///
    /// [STUN-PATH-CHAR]: https://w3.org/TR/webrtc-stats#bib-stun-path-char
    /// [RFC 7675]: https://tools.ietf.org/html/rfc7675
    double? currentRoundTripTime,

    /// Calculated by the underlying congestion control by combining the
    /// available bitrate for all the outgoing RTP streams using this
    /// candidate pair. The bitrate measurement does not count the size of
    /// the IP or other transport layers like TCP or UDP. It is similar to
    /// the TIAS defined in [RFC 3890], i.e. it is measured in bits per
    /// second and the bitrate is calculated over a 1 second window.
    ///
    /// Implementations that do not calculate a sender-side estimate MUST
    /// leave this undefined. Additionally, the value MUST be undefined for
    /// candidate pairs that were never used. For pairs in use, the estimate
    /// is normally no lower than the bitrate for the packets sent at
    /// [lastPacketSentTimestamp][1], but might be higher. For candidate
    /// pairs that are not currently in use but were used before,
    /// implementations MUST return undefined.
    ///
    /// [RFC 3890]: https://tools.ietf.org/html/rfc3890
    /// [1]: https://tinyurl.com/rfc72eh
    double? availableOutgoingBitrate,
  }) = RtcStatsType_RtcIceCandidatePairStats;

  /// Transport statistics related to the [RTCPeerConnection] object.
  ///
  /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
  const factory RtcStatsType.rtcTransportStats({
    /// Total number of packets sent over this transport.
    BigInt? packetsSent,

    /// Total number of packets received on this transport.
    BigInt? packetsReceived,

    /// Total number of payload bytes sent on this [RTCPeerConnection], i.e.
    /// not including headers or padding.
    ///
    /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
    BigInt? bytesSent,

    /// Total number of bytes received on this [RTCPeerConnection], i.e. not
    /// including headers or padding.
    ///
    /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
    BigInt? bytesReceived,

    /// Set to the current value of the [role][1] of the underlying
    /// [RTCDtlsTransport][2]'s [transport][3].
    ///
    /// [1]: https://w3.org/TR/webrtc#dom-icetransport-role
    /// [2]: https://w3.org/TR/webrtc#rtcdtlstransport-interface
    /// [3]: https://w3.org/TR/webrtc#dom-rtcdtlstransport-icetransport
    IceRole? iceRole,
  }) = RtcStatsType_RtcTransportStats;

  /// Statistics for the remote endpoint's inbound [RTP] stream corresponding
  /// to an outbound stream that is currently sent with [RTCPeerConnection]
  /// object.
  ///
  /// It is measured at the remote endpoint and reported in a RTCP Receiver
  /// Report (RR) or RTCP Extended Report (XR).
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
  const factory RtcStatsType.rtcRemoteInboundRtpStreamStats({
    /// [localId] is used for looking up the local
    /// [RTCOutboundRtpStreamStats][1] object for the same [SSRC].
    ///
    /// [localId]: https://tinyurl.com/r8uhbo9
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    /// [1]: https://w3.org/TR/webrtc-stats#dom-rtcoutboundrtpstreamstats
    String? localId,

    /// Packet jitter measured in seconds for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    double? jitter,

    /// Estimated round trip time for this [SSRC] based on the RTCP
    /// timestamps in the RTCP Receiver Report (RR) and measured in seconds.
    /// Calculated as defined in [Section 6.4.1 of RFC 3550][1].
    /// If no RTCP Receiver Report is received with a DLSR value other than
    /// 0, the round trip time is left undefined.
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    /// [1]: https://tools.ietf.org/html/rfc3550#section-6.4.1
    double? roundTripTime,

    /// Fraction packet loss reported for this [SSRC].
    /// Calculated as defined in [Section 6.4.1 of RFC 3550][1] and
    /// [Appendix A.3][2].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    /// [1]: https://tools.ietf.org/html/rfc3550#section-6.4.1
    /// [2]: https://tools.ietf.org/html/rfc3550#appendix-A.3
    double? fractionLost,

    /// Total number of RTCP RR blocks received for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    BigInt? reportsReceived,

    /// Total number of RTCP RR blocks received for this [SSRC] that contain
    /// a valid round trip time. This counter will increment if the
    /// [roundTripTime] is undefined.
    ///
    /// [roundTripTime]: https://tinyurl.com/ssg83hq
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    int? roundTripTimeMeasurements,
  }) = RtcStatsType_RtcRemoteInboundRtpStreamStats;

  /// Statistics for the remote endpoint's outbound [RTP] stream corresponding
  /// to an inbound stream that is currently received with [RTCPeerConnection]
  /// object.
  ///
  /// It is measured at the remote endpoint and reported in an RTCP Sender
  /// Report (SR).
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  /// [RTCPeerConnection]: https://w3.org/TR/webrtc#dom-rtcpeerconnection
  const factory RtcStatsType.rtcRemoteOutboundRtpStreamStats({
    /// [localId] is used for looking up the local
    /// [RTCInboundRtpStreamStats][1] object for the same [SSRC].
    ///
    /// [localId]: https://tinyurl.com/vu9tb2e
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    /// [1]: https://w3.org/TR/webrtc-stats#dom-rtcinboundrtpstreamstats
    String? localId,

    /// [remoteTimestamp] (as [HIGHRES-TIME]) is the remote timestamp at
    /// which these statistics were sent by the remote endpoint. This
    /// differs from timestamp, which represents the time at which the
    /// statistics were generated or received by the local endpoint. The
    /// [remoteTimestamp], if present, is derived from the NTP timestamp in
    /// an RTCP Sender Report (SR) block, which reflects the remote
    /// endpoint's clock. That clock may not be synchronized with the local
    /// clock.
    ///
    /// [HIGRES-TIME]: https://w3.org/TR/webrtc-stats#bib-highres-time
    /// [remoteTimestamp]: https://tinyurl.com/rzlhs87
    double? remoteTimestamp,

    /// Total number of RTCP SR blocks sent for this [SSRC].
    ///
    /// [SSRC]: https://w3.org/TR/webrtc-stats#dfn-ssrc
    BigInt? reportsSent,
  }) = RtcStatsType_RtcRemoteOutboundRtpStreamStats;

  /// Unimplemented stats.
  const factory RtcStatsType.unimplemented() = RtcStatsType_Unimplemented;
}

/// Representation of a track event, sent when a new [`MediaStreamTrack`] is
/// added to an [`RtcRtpTransceiver`] as part of a [`PeerConnection`].
class RtcTrackEvent {
  /// [`MediaStreamTrack`] associated with the [RTCRtpReceiver] identified
  /// by the receiver.
  ///
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  final MediaStreamTrack track;

  /// [`RtcRtpTransceiver`] object associated with the event.
  final RtcRtpTransceiver transceiver;

  const RtcTrackEvent({required this.track, required this.transceiver});

  @override
  int get hashCode => track.hashCode ^ transceiver.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcTrackEvent &&
          runtimeType == other.runtimeType &&
          track == other.track &&
          transceiver == other.transceiver;
}

/// [RTCP] feedback message intended to enable congestion control for
/// interactive real-time traffic using [RTP].
///
/// [RTCP]: https://en.wikipedia.org/wiki/RTP_Control_Protocol
/// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
class RtcpFeedback {
  /// Message type of this [`RtcpFeedback`].
  final RtcpFeedbackMessageType? messageType;

  /// Kind of this [`RtcpFeedback`].
  final RtcpFeedbackType kind;

  const RtcpFeedback({this.messageType, required this.kind});

  @override
  int get hashCode => messageType.hashCode ^ kind.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtcpFeedback &&
          runtimeType == other.runtimeType &&
          messageType == other.messageType &&
          kind == other.kind;
}

/// Possible message types of an [`RtcpFeedback`], when is type is
/// [`RtcpFeedbackType::Nack`] or [`RtcpFeedbackType::Ccm`].
enum RtcpFeedbackMessageType {
  /// Equivalent to `{ type: "nack", parameter: undefined }` in ORTC.
  genericNack,

  /// Usable with [`RtcpFeedbackType::Nack`].
  pli,

  /// Usable with [`RtcpFeedbackType::Ccm`].
  fir,
}

/// Possible types of an [`RtcpFeedback`].
enum RtcpFeedbackType {
  /// Codec control messages.
  ccm,

  /// Loss notification feedback.
  lntf,

  /// Negative acknowledgemen.
  nack,

  /// Receiver estimated maximum bitrate.
  remb,

  /// Transport wide congestion control.
  transportCc,
}

/// Representation of the static capabilities of an endpoint.
///
/// Applications can use these capabilities to construct [`RtpParameters`].
class RtpCapabilities {
  /// Supported codecs.
  final List<RtpCodecCapability> codecs;

  /// Supported [RTP] header extensions.
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  final List<RtpHeaderExtensionCapability> headerExtensions;

  const RtpCapabilities({required this.codecs, required this.headerExtensions});

  @override
  int get hashCode => codecs.hashCode ^ headerExtensions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtpCapabilities &&
          runtimeType == other.runtimeType &&
          codecs == other.codecs &&
          headerExtensions == other.headerExtensions;
}

/// Representation of static capabilities of an endpoint's implementation of a
/// codec.
class RtpCodecCapability {
  /// Default payload type for the codec.
  ///
  /// Mainly needed for codecs that have statically assigned payload types.
  final int? preferredPayloadType;

  /// List of [`ScalabilityMode`]s supported by the video codec.
  final List<ScalabilityMode> scalabilityModes;

  /// Built [MIME "type/subtype"][0] string from `name` and `kind`.
  ///
  /// [0]: https://en.wikipedia.org/wiki/Media_type
  final String mimeType;

  /// Used to identify the codec. Equivalent to [MIME subtype][0].
  ///
  /// [0]: https://en.wikipedia.org/wiki/Media_type#Subtypes
  final String name;

  /// [`MediaType`] of this codec. Equivalent to [MIME] top-level type.
  ///
  /// [MIME]: https://en.wikipedia.org/wiki/Media_type
  final MediaType kind;

  /// If [`None`], the implementation default is used.
  final int? clockRate;

  /// Number of audio channels used.
  ///
  /// [`None`] for video codecs.
  ///
  /// If [`None`] for audio, the implementation default is used.
  final int? numChannels;

  /// Codec-specific parameters that must be signaled to the remote party.
  ///
  /// Corresponds to `a=fmtp` parameters in [SDP].
  ///
  /// Contrary to ORTC, these parameters are named using all lowercase
  /// strings. This helps make the mapping to [SDP] simpler, if an application
  /// is using [SDP]. Boolean values are represented by the string "1".
  ///
  /// [SDP]: https://en.wikipedia.org/wiki/Session_Description_Protocol
  final List<(String, String)> parameters;

  /// Feedback mechanisms to be used for this codec.
  final List<RtcpFeedback> feedback;

  const RtpCodecCapability({
    this.preferredPayloadType,
    required this.scalabilityModes,
    required this.mimeType,
    required this.name,
    required this.kind,
    this.clockRate,
    this.numChannels,
    required this.parameters,
    required this.feedback,
  });

  @override
  int get hashCode =>
      preferredPayloadType.hashCode ^
      scalabilityModes.hashCode ^
      mimeType.hashCode ^
      name.hashCode ^
      kind.hashCode ^
      clockRate.hashCode ^
      numChannels.hashCode ^
      parameters.hashCode ^
      feedback.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtpCodecCapability &&
          runtimeType == other.runtimeType &&
          preferredPayloadType == other.preferredPayloadType &&
          scalabilityModes == other.scalabilityModes &&
          mimeType == other.mimeType &&
          name == other.name &&
          kind == other.kind &&
          clockRate == other.clockRate &&
          numChannels == other.numChannels &&
          parameters == other.parameters &&
          feedback == other.feedback;
}

/// Representation of capabilities/preferences of an implementation for a header
/// extension of [`RtpCapabilities`].
class RtpHeaderExtensionCapability {
  /// [URI] of this extension, as defined in [RFC 8285].
  ///
  /// [RFC 8285]: https://tools.ietf.org/html/rfc8285
  /// [URI]: https://en.wikipedia.org/wiki/Uniform_Resource_Identifier
  final String uri;

  /// Preferred value of ID that goes in the packet.
  final int? preferredId;

  /// If [`true`], it's preferred that the value in the header is encrypted.
  final bool preferredEncrypted;

  /// Direction of the extension.
  ///
  /// [`RtpTransceiverDirection::Stopped`] value is only used with
  /// `RtpTransceiverInterface::SetHeaderExtensionsToNegotiate()` and
  /// `SetHeaderExtensionsToNegotiate()`.
  final RtpTransceiverDirection direction;

  const RtpHeaderExtensionCapability({
    required this.uri,
    this.preferredId,
    required this.preferredEncrypted,
    required this.direction,
  });

  @override
  int get hashCode =>
      uri.hashCode ^
      preferredId.hashCode ^
      preferredEncrypted.hashCode ^
      direction.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtpHeaderExtensionCapability &&
          runtimeType == other.runtimeType &&
          uri == other.uri &&
          preferredId == other.preferredId &&
          preferredEncrypted == other.preferredEncrypted &&
          direction == other.direction;
}

/// [RTCRtpTransceiverDirection][1] representation.
///
/// [1]: https://w3.org/TR/webrtc#dom-rtcrtptransceiverdirection
enum RtpTransceiverDirection {
  /// The [RTCRtpTransceiver]'s [RTCRtpSender] will offer to send RTP, and
  /// will send RTP if the remote peer accepts. The [RTCRtpTransceiver]'s
  /// [RTCRtpReceiver] will offer to receive RTP, and will receive RTP if the
  /// remote peer accepts.
  ///
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpTransceiver]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver
  sendRecv,

  /// The [RTCRtpTransceiver]'s [RTCRtpSender] will offer to send RTP, and
  /// will send RTP if the remote peer accepts. The [RTCRtpTransceiver]'s
  /// [RTCRtpReceiver] will not offer to receive RTP, and will not receive
  /// RTP.
  ///
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpTransceiver]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver
  sendOnly,

  /// The [RTCRtpTransceiver]'s [RTCRtpSender] will not offer to send RTP,
  /// and will not send RTP. The [RTCRtpTransceiver]'s [RTCRtpReceiver] will
  /// offer to receive RTP, and will receive RTP if the remote peer accepts.
  ///
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpTransceiver]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver
  recvOnly,

  /// The [RTCRtpTransceiver]'s [RTCRtpSender] will not offer to send RTP,
  /// and will not send RTP. The [RTCRtpTransceiver]'s [RTCRtpReceiver] will
  /// not offer to receive RTP, and will not receive RTP.
  ///
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpTransceiver]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver
  inactive,

  /// The [RTCRtpTransceiver] will neither send nor receive RTP. It will
  /// generate a zero port in the offer. In answers, its [RTCRtpSender] will
  /// not offer to send RTP, and its [RTCRtpReceiver] will not offer to
  /// receive RTP. This is a terminal state.
  ///
  /// [RTCRtpReceiver]: https://w3.org/TR/webrtc#dom-rtcrtpreceiver
  /// [RTCRtpSender]: https://w3.org/TR/webrtc#dom-rtcrtpsender
  /// [RTCRtpTransceiver]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver
  stopped,
}

/// Representation of an [RTCRtpTransceiverInit][0].
///
/// [0]: https://w3.org/TR/webrtc#dom-rtcrtptransceiverinit
class RtpTransceiverInit {
  /// Direction of the [RTCRtpTransceiver].
  ///
  /// [RTCRtpTransceiver]: https://w3.org/TR/webrtc#dom-rtcrtptransceiver
  final RtpTransceiverDirection direction;

  /// Sequence containing parameters for sending [RTP] encodings of media.
  ///
  /// [RTP]: https://en.wikipedia.org/wiki/Real-time_Transport_Protocol
  final List<RtcRtpEncodingParameters> sendEncodings;

  const RtpTransceiverInit({
    required this.direction,
    required this.sendEncodings,
  });

  @override
  int get hashCode => direction.hashCode ^ sendEncodings.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is RtpTransceiverInit &&
          runtimeType == other.runtimeType &&
          direction == other.direction &&
          sendEncodings == other.sendEncodings;
}

/// [ScalabilityMode][0] representation.
///
/// [0]: https://tinyurl.com/35ae3mbe
enum ScalabilityMode {
  /// [ScalabilityMode.L1T1][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L1T1*
  l1T1,

  /// [ScalabilityMode.L1T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L1T2*
  l1T2,

  /// [ScalabilityMode.L1T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L1T3*
  l1T3,

  /// [ScalabilityMode.L2T1][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T1*
  l2T1,

  /// [ScalabilityMode.L2T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T1*
  l2T1H,

  /// [ScalabilityMode.L2T1_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T1_KEY*
  l2T1Key,

  /// [ScalabilityMode.L2T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T2h*
  l2T2,

  /// [ScalabilityMode.L2T2h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T2*
  l2T2H,

  /// [ScalabilityMode.L2T2_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T2_KEY*
  l2T2Key,

  /// [ScalabilityMode.L2T2_KEY_SHIFT][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T2_KEY_SHIFT*
  l2T2KeyShift,

  /// [ScalabilityMode.L2T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T3*
  l2T3,

  /// [ScalabilityMode.L2T3h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T3*
  l2T3H,

  /// [ScalabilityMode.L2T3_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L2T3_KEY*
  l2T3Key,

  /// [ScalabilityMode.L3T1][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T1*
  l3T1,

  /// [ScalabilityMode.L3T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T1*
  l3T1H,

  /// [ScalabilityMode.L3T1_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T1_KEY*
  l3T1Key,

  /// [ScalabilityMode.L3T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T2h*
  l3T2,

  /// [ScalabilityMode.L3T2h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T2*
  l3T2H,

  /// [ScalabilityMode.L3T2_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T2_KEY*
  l3T2Key,

  /// [ScalabilityMode.kL3T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kL3T3*
  l3T3,

  /// [ScalabilityMode.kL3T3h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kL3T3*
  l3T3H,

  /// [ScalabilityMode.kL3T3_KEY][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#L3T3_KEY*
  l3T3Key,

  /// [ScalabilityMode.kS2T1][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kS2T1*
  s2T1,

  /// [ScalabilityMode.kS2T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kS2T1*
  s2T1H,

  /// [ScalabilityMode.kS2T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kS2T2*
  s2T2,

  /// [ScalabilityMode.kS2T2h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#kS2T2*
  s2T2H,

  /// [ScalabilityMode.S2T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S2T3h*
  s2T3,

  /// [ScalabilityMode.S2T3h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S2T3*
  s2T3H,

  /// [ScalabilityMode.S3T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T1*
  s3T1,

  /// [ScalabilityMode.S3T1h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T1*
  s3T1H,

  /// [ScalabilityMode.S3T2][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T2*
  s3T2,

  /// [ScalabilityMode.S3T2h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T2*
  s3T2H,

  /// [ScalabilityMode.S3T3][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T3*
  s3T3,

  /// [ScalabilityMode.S3T3h][0] mode.
  ///
  /// [0]: https://w3.org/TR/webrtc-svc#S3T3*
  s3T3H,
}

/// [RTCSdpType] representation.
///
/// [RTCSdpType]: https://w3.org/TR/webrtc#dom-rtcsdptype
enum SdpType {
  /// [RTCSdpType.offer][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsdptype-offer
  offer,

  /// [RTCSdpType.pranswer][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsdptype-pranswer
  prAnswer,

  /// [RTCSdpType.answer][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsdptype-answer
  answer,

  /// [RTCSdpType.rollback][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsdptype-rollback
  rollback,
}

/// [RTCSignalingState] representation.
///
/// [RTCSignalingState]: https://w3.org/TR/webrtc#state-definitions
enum SignalingState {
  /// [RTCSignalingState.stable][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsignalingstate-stable
  stable,

  /// [RTCSignalingState.have-local-offer][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsignalingstate-have-local-offer
  haveLocalOffer,

  /// [RTCSignalingState.have-local-pranswer][1] representation.
  ///
  /// [1]: https://tinyurl.com/have-local-pranswer
  haveLocalPrAnswer,

  /// [RTCSignalingState.have-remote-offer][1] representation.
  ///
  /// [1]: https://tinyurl.com/have-remote-offer
  haveRemoteOffer,

  /// [RTCSignalingState.have-remote-pranswer][1] representation.
  ///
  /// [1]: https://tinyurl.com/have-remote-pranswer
  haveRemotePrAnswer,

  /// [RTCSignalingState.closed][1] representation.
  ///
  /// [1]: https://w3.org/TR/webrtc#dom-rtcsignalingstate-closed
  closed,
}

@freezed
sealed class TrackEvent with _$TrackEvent {
  const TrackEvent._();

  /// Ended event of the [`MediaStreamTrack`] interface is fired when playback
  /// or streaming has stopped because the end of the media was reached or
  /// because no further data is available.
  const factory TrackEvent.ended() = TrackEvent_Ended;

  /// Event indicating an audio level change in the [`MediaStreamTrack`].
  const factory TrackEvent.audioLevelUpdated(int field0) =
      TrackEvent_AudioLevelUpdated;

  /// Event indicating that the [`MediaStreamTrack`] has completely
  /// initialized and can be used on Flutter side.
  const factory TrackEvent.trackCreated() = TrackEvent_TrackCreated;
}

/// Indicator of the current [MediaStreamTrackState][0] of a
/// [`MediaStreamTrack`].
///
/// [0]: https://w3.org/TR/mediacapture-streams#dom-mediastreamtrackstate
enum TrackState {
  /// [MediaStreamTrackState.live][0] representation.
  ///
  /// [0]: https://tinyurl.com/w3mcs#idl-def-MediaStreamTrackState.live
  live,

  /// [MediaStreamTrackState.ended][0] representation.
  ///
  /// [0]: https://tinyurl.com/w3mcs#idl-def-MediaStreamTrackState.ended
  ended,
}

/// Supported video codecs.
enum VideoCodec {
  /// [AV1] AOMedia Video 1.
  ///
  /// [AV1]: https://en.wikipedia.org/wiki/AV1
  av1,

  /// [H.264] Advanced Video Coding (AVC).
  ///
  /// [H.264]: https://en.wikipedia.org/wiki/Advanced_Video_Coding
  h264,

  /// [H.265] High Efficiency Video Coding (HEVC).
  ///
  /// [H.265]: https://en.wikipedia.org/wiki/High_Efficiency_Video_Coding
  h265,

  /// [VP8] codec.
  ///
  /// [VP8]: https://en.wikipedia.org/wiki/VP8
  vp8,

  /// [VP9] codec.
  ///
  /// [VP9]: https://en.wikipedia.org/wiki/VP9
  vp9,
}

/// [`VideoCodec`] info for encoding/decoding.
class VideoCodecInfo {
  /// Indicator whether hardware acceleration should be used.
  final bool isHardwareAccelerated;

  /// [`VideoCodec`] to be used for encoding/decoding.
  final VideoCodec codec;

  const VideoCodecInfo({
    required this.isHardwareAccelerated,
    required this.codec,
  });

  @override
  int get hashCode => isHardwareAccelerated.hashCode ^ codec.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is VideoCodecInfo &&
          runtimeType == other.runtimeType &&
          isHardwareAccelerated == other.isHardwareAccelerated &&
          codec == other.codec;
}

/// Nature and settings of the video [`MediaStreamTrack`] returned by
/// [`Webrtc::get_media()`].
class VideoConstraints {
  /// Identifier of the device generating the content of the
  /// [`MediaStreamTrack`].
  ///
  /// First device will be chosen if an empty [`String`] is provided.
  final String? deviceId;

  /// Width in pixels.
  final int width;

  /// Height in pixels.
  final int height;

  /// Exact frame rate (frames per second).
  final int frameRate;

  /// Indicator whether the request video track should be acquired via screen
  /// capturing.
  final bool isDisplay;

  const VideoConstraints({
    this.deviceId,
    required this.width,
    required this.height,
    required this.frameRate,
    required this.isDisplay,
  });

  @override
  int get hashCode =>
      deviceId.hashCode ^
      width.hashCode ^
      height.hashCode ^
      frameRate.hashCode ^
      isDisplay.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is VideoConstraints &&
          runtimeType == other.runtimeType &&
          deviceId == other.deviceId &&
          width == other.width &&
          height == other.height &&
          frameRate == other.frameRate &&
          isDisplay == other.isDisplay;
}
